{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91f1a81-f38b-4be7-bc40-e036d38d0726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Starting ArgyTrif\"\n",
      "\n",
      " Reading data file: ArgyTrif/dart_raw/Report_DArg23-8132_SNP_singlerow.csv \n",
      " Initial data scan -- \n",
      "   Samples:  424  \n",
      "   SNPs:  17627  \n",
      "   Loci:  15520  \n",
      "\n",
      " Creating a DArT data list containing:                       \n",
      "             Genotypes                    --  $gt            \n",
      "             Sample Names                 --  $sample_names  \n",
      "             Locus Names                  --  $locus_names   \n",
      "             Locus Reproducibility Scores --  $locus_repro   \n",
      "             Position of SNP in locus     --  $locus_pos     \n",
      "             Data filtering treatments    --  $treatment     \n",
      "             Position of SNP in locus     --  $locus_pos     \n",
      "             Method of data encoding gt   --  $encoding      \n",
      "             Nucleotides in this SNP      --  $locus_nuc     \n",
      "\n",
      " DArT object found with dart encoding (0=hom ref; 1=hom alt; 2=het) \n",
      " Rewriting with altcount encoding     (0=hom ref; 1=het; 2=hom alt) \n",
      "  QC directory:  ArgyTrif/qual_stat/raw  already exists, content will be overwritten. \n",
      "  QC calculations starting \n",
      "  QC report in ArgyTrif/qual_stat/raw/\n",
      " Data reproducibility stats found, finding values less than  0.96 \n",
      " Found  1103  loci with reproducibility <=  0.96  returning their indices \n",
      " Missing data stats calculated, finding values less than  0.2 \n",
      " Found  13846  loci with missingness >=  0.2  returning their indices \n",
      " Returning missing and low reproducibility snps as bad \n",
      "  QC directory:  ArgyTrif/qual_stat/raw_SNPFilt  already exists, content will be overwritten. \n",
      "  QC calculations starting \n",
      "  QC report in ArgyTrif/qual_stat/raw_SNPFilt/\n",
      "   Choosing one snp per CloneID at random\n",
      "   Using random seed: 12345 \n",
      "  QC calculations starting \n",
      " genotypes, lous names read \n",
      " found  487 clones with multiple SNPs \n",
      " choosing one snp at random from each, which could take a while \n",
      " A new SNP set has been selected, writing to a data object \n",
      "  QC directory:  ArgyTrif/qual_stat/raw_SNPFilt_1SNPperClone  already exists, content will be overwritten. \n",
      "  QC calculations starting \n",
      "  QC report in ArgyTrif/qual_stat/raw_SNPFilt_1SNPperClone/\n",
      "\n",
      " Reading data file: ArgyTrif/meta/ArgyTrif_DArg23-8132_meta.xlsx \n",
      " Found sample, lat and long columns in metadata \n",
      " Found metadata for  436  samples \n",
      " This includes overlap with  424  samples \n",
      " out of  424 in DArT genotypes \n",
      " Adding analysis fields to meta data list \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'notes'</li><li>'NurseryPopsKinship'</li><li>'BigScrubRegionPopsNoNursery'</li><li>'BigScrubRegionPopsWithNursery'</li><li>'AllPopsNoNursery'</li><li>'AllPopsWithNursery'</li><li>'Clades'</li><li>'SouthernPops'</li><li>'nationalPark'</li><li>'natureReserve'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'notes'\n",
       "\\item 'NurseryPopsKinship'\n",
       "\\item 'BigScrubRegionPopsNoNursery'\n",
       "\\item 'BigScrubRegionPopsWithNursery'\n",
       "\\item 'AllPopsNoNursery'\n",
       "\\item 'AllPopsWithNursery'\n",
       "\\item 'Clades'\n",
       "\\item 'SouthernPops'\n",
       "\\item 'nationalPark'\n",
       "\\item 'natureReserve'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'notes'\n",
       "2. 'NurseryPopsKinship'\n",
       "3. 'BigScrubRegionPopsNoNursery'\n",
       "4. 'BigScrubRegionPopsWithNursery'\n",
       "5. 'AllPopsNoNursery'\n",
       "6. 'AllPopsWithNursery'\n",
       "7. 'Clades'\n",
       "8. 'SouthernPops'\n",
       "9. 'nationalPark'\n",
       "10. 'natureReserve'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"notes\"                         \"NurseryPopsKinship\"           \n",
       " [3] \"BigScrubRegionPopsNoNursery\"   \"BigScrubRegionPopsWithNursery\"\n",
       " [5] \"AllPopsNoNursery\"              \"AllPopsWithNursery\"           \n",
       " [7] \"Clades\"                        \"SouthernPops\"                 \n",
       " [9] \"nationalPark\"                  \"natureReserve\"                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Removing Bilborough Springbrook with  with a sample size of 3 samples\"\n",
      "[1] \"Removing Blackbutt with  with a sample size of 4 samples\"\n",
      "[1] \"Removing ANBG ex-situ Mt Nardi with  with a sample size of 1 samples\"\n",
      " Data found in altcount encoding, search for fixed sites commencing \n",
      " Found  640  loci with MAC lte  0  returning their indices \n",
      " Found  640 fixed SNPs, these will be removed from DArT object \n",
      " Samples successfully matched and ordered: merging dart and meta objects \n",
      " Data found in altcount encoding, search for fixed sites commencing \n",
      " Found  172  loci with MAC lte  0  returning their indices \n",
      " Found  172 fixed SNPs, these will be removed from DArT object \n",
      " Samples successfully matched and ordered: merging dart and meta objects \n",
      "  Dart standard directory:  ArgyTrif/dart_standard  already exists... content might be overwritten. \n",
      "  Standard directory:  ArgyTrif/dart_standard/raw_SNPFilt_1SNPperClone_Field_AllPopsNoNursery  already exists, content will be overwritten. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "2208"
      ],
      "text/latex": [
       "2208"
      ],
      "text/markdown": [
       "2208"
      ],
      "text/plain": [
       "[1] 2208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 't_num_indv', 'n_Sites_sel', 'combined'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22mScale for \u001b[32mfill\u001b[39m is already present.\n",
      "Adding another scale for \u001b[32mfill\u001b[39m, which will replace the existing scale.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"AlleleProp analysis for ArgyTrif AllPopsNoNursery complete\"\n",
      "[1] \"not running OptSiteMix for minimum Sites\"\n",
      "[1] \"not running OptSiteMix for minimum samples\"\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"pacman\")\n",
    "library(pacman)\n",
    "pacman::p_load(gghighlight, ade4,  adegenet,  animation,  ape,  car,  caTools,  cowplot,  dartR,  devtools,  diveRsity,  dplyr, stringr, gganimate,  ggh4x,  ggplot2,  ggrepel,  grid,  gridExtra,  LEA,  magick,  mapplots,  OptGenMix,  oz,  ozmaps,  plyr,  poppr,  readxl,  reshape2,  rgl,  RRtools,  sfsCalcs,  tidyr,  tiff,  vegan,  webshot2, geosphere, HWxtest, phangorn, forcats, phytools) \n",
    "load(\"/home/richard/Packages/PSFsaved_scripts4autom.R\")\n",
    "maindir<- \"/home/richard/rrspecies/\"\n",
    "RandRbase <- \"\"\n",
    "setwd(maindir)\n",
    "spls <- read.csv(paste0(maindir,\"RRSpeciesParameters.csv\"),header = TRUE)\n",
    "nsp <- length(spls$species) #number of species\n",
    "\n",
    "\n",
    "#for (z in 1:nsp){\n",
    "z=1 # change this to the desired row you want to analyse from your RRParameters file\n",
    "    \n",
    "    species <- spls$species[z]\n",
    "    dataset <- spls$dataset[z]\n",
    "    analysis <- spls$analysis[z]\n",
    "    topskip   <- spls$topskip[z]\n",
    "    nmetavar   <- spls$nmetavar[z]\n",
    "    max_missing <- spls$max_missing[z] #default is 0.2\n",
    "    OptSiteMixMinSites <- spls$Run_OptSiteMix_minimum_Sites[z]\n",
    "    OptSiteMixMinSamples <- spls$Run_OptSiteMix_minimum_samples[z]\n",
    "    ForcedOptSiteMix <- spls$Run_forced_OptSiteMix[z]\n",
    "    ListForcedSites <- spls$List_of_ForcedSites[z]\n",
    "    thresh_maf <- spls$threshold_maf[z] #deafult 0.03 change to higher if singleton is stronger possibility e.g Cattai\n",
    "    samplingthreshold <- spls$threshold_allele_prop[z] # deafult 0.9 the threshold value would want all sampling combinations to be over for allele prop script \n",
    "\n",
    "    num_steps <- 2000   #default of 2000 steps    \n",
    "    rand_numsteps <- 100 #deafult of 100 randomisations\n",
    "\n",
    "    print(paste0(\"Starting \",species))\n",
    "\n",
    "    d1        <- read.dart.xls.onerow(RandRbase,species,dataset,topskip, nmetavar, euchits=FALSE)\n",
    "    qc1       <- report.dart.qc.stats(d1, RandRbase, species, dataset, threshold_missing_loci = 0.8) # threshold_missing_loci: check which samples have 80% missing loci\n",
    "    d2        <- remove.poor.quality.snps(d1, min_repro=0.96, max_missing=max_missing) \n",
    "    qc2       <- report.dart.qc.stats(d2, RandRbase, species, dataset)\n",
    "    d3        <- sample.one.snp.per.locus.random(d2, seed=12345)\n",
    "    qc3       <- report.dart.qc.stats(d3, RandRbase, species, dataset)\n",
    "    m1        <- read.meta.data(d3, RandRbase, species, dataset, fields=10); colnames(m1$analyses)\n",
    "\n",
    "    outputloc <- paste0(maindir, species, \"/output_\", analysis)\n",
    "    outputloc2 <- paste0(maindir, species, \"/output_\", analysis,\"/\")\n",
    "\n",
    "    subDir <-paste0(outputloc2)\n",
    "    if(!dir.exists(file.path(subDir))){\n",
    "        dir.create(file.path(subDir))\n",
    "    }\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "   #create a temp meta dataframe to remove Sites/samples that include less than X individuals\n",
    "    temp<-as.data.frame(m1$analyses)\n",
    "\n",
    "    samplethreshold <-5                     # change this to what number of samples you want toi have uniform across all pops\n",
    "\n",
    "\n",
    "  \n",
    "#### Below lines remove Sites with less than threshold number of samples, and subsample Sites that are above the threshold\n",
    "\n",
    "    for (x in unique(na.omit(temp[,analysis]))) {\n",
    "        pop_samples <- which(temp[,analysis] == x)\n",
    "        if (length(pop_samples) < samplethreshold) {\n",
    "            temp[, analysis]<-gsub(x, replacement=NA, temp[, analysis])\n",
    "            #print(paste0(\"Removing \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))\n",
    "        }\n",
    "    \n",
    "        if (length(pop_samples) == samplethreshold) {\n",
    "        #print(paste0(\"Keeping \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))\n",
    "    \n",
    "        }\n",
    "    \n",
    "        if (length(pop_samples) > samplethreshold) {\n",
    "      \n",
    "            subsamplepops <- pop_samples[sample(1:length(pop_samples), size=samplethreshold, replace = F)]\n",
    "      \n",
    "            for (b in 1:length(pop_samples)){\n",
    "                if (pop_samples[b] %in% subsamplepops == FALSE){ \n",
    "                    temp[, analysis][pop_samples[b]] <- NA\n",
    "                }\n",
    "                #print(paste0(\"Reducing \",x, \" to a sample size of \", samplethreshold,\" samples\"))\n",
    "            }\n",
    "    \n",
    "        } else {}\n",
    "    }\n",
    "\n",
    "\n",
    "### If you want to just remove any sites that are below the threshold (but keep individuals that are above a threshold, then unhash the below section)\n",
    "# for (x in unique(na.omit(temp[, analysis]))) {\n",
    "#   pop_samples <- which(temp[, analysis] == x)\n",
    "#   if (length(pop_samples) < samplethreshold) {\n",
    "#     temp[, analysis]<-gsub(x, replacement=NA, temp[, analysis])\n",
    "#     print(paste0(\"Removing \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))\n",
    "#   } else {}\n",
    "# }\n",
    "\n",
    "\n",
    "    \n",
    "    m1$analyses<-temp\n",
    "    dm <- dart.meta.data.merge(d3, m1)\n",
    "    fields    <- c(analysis) \n",
    "    dms     <- data.by.meta.fields(dm, fields, RandRbase, species, dataset, object=analysis); #print(dms$meta$analyses[,analysis])\n",
    "    #correct inconsistencies in J's scripts for naming treatment which is for naming files\n",
    "    treatment <- paste0(\"raw_SNPFilt_1SNPperClone_Field_\", analysis)\n",
    "    dms$treatment <- treatment  \n",
    "    gta <- dms$gt \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#             █████╗ ██╗     ██╗     ███████╗██╗     ███████╗    ██████╗ ██████╗  ██████╗ ██████╗ \n",
    "#            ██╔══██╗██║     ██║     ██╔════╝██║     ██╔════╝    ██╔══██╗██╔══██╗██╔═══██╗██╔══██╗\n",
    "#            ███████║██║     ██║     █████╗  ██║     █████╗      ██████╔╝██████╔╝██║   ██║██████╔╝\n",
    "#            ██╔══██║██║     ██║     ██╔══╝  ██║     ██╔══╝      ██╔═══╝ ██╔══██╗██║   ██║██╔═══╝ \n",
    "#            ██║  ██║███████╗███████╗███████╗███████╗███████╗    ██║     ██║  ██║╚██████╔╝██║     \n",
    "#            ╚═╝  ╚═╝╚══════╝╚══════╝╚══════╝╚══════╝╚══════╝    ╚═╝     ╚═╝  ╚═╝ ╚═════╝ ╚═╝     \n",
    "                                                                                        \n",
    "  \n",
    "  \n",
    "    ##### Allele proportion vs Number of Sites/Total Samples #####\n",
    "    \n",
    " \n",
    "  \n",
    "    ###steps here are to remove missingness ###can be ignored if high missingness\n",
    "    ###if ignored, make sure MUST do testing on amount of missing data (make sure 10,20,30% cutoff yields similar optgenmix results)\n",
    "    ###if you want to remove all missingness (recommended sometimes use the first hashed out section. otherwise use the second)\n",
    "    #cones GT matrix in new variable (ColID are SNPIDs)\n",
    "    gt_sw_comp <- gta    \n",
    "    ncol(gt_sw_comp)    \n",
    "    #removes columns with ANY missingness\n",
    "    # gt_sw_comp <- gt_sw_comp[  , which(colSums(gt_sw_comp, na.rm = ) > 0 & colSums(gt_sw_comp) < nrow(gt_sw_comp)*2) ] ###unhash this no missingness\n",
    "    # ncol(gt_sw_comp)  ###unhash this no missingness\n",
    "    subDir <-paste0(outputloc2, \"OptSiteMix/\")\n",
    "  \n",
    "    if(!dir.exists(file.path(subDir))){\n",
    "        dir.create(file.path(subDir))\n",
    "    }\n",
    "  \n",
    "    subDir <-paste0(outputloc2, \"OptSiteMix/Allele_Proportion/\")\n",
    "    if(!dir.exists(file.path(subDir))){\n",
    "        dir.create(file.path(subDir))\n",
    "    }\n",
    "  \n",
    "\n",
    "    ###load required code\n",
    "    source(\"/home/richard/Packages/common_allele_count.r\")\n",
    "    source(\"/home/richard/Packages/get_maf.r\")\n",
    "    # source(\"C:/Users/DimonR/OneDrive - DPIE/R/Packages/guide_axis_nested.r\")\n",
    "\n",
    "    ###Create a table with all possible combinations of sampling assuming all included pops have atleast 5 samples available\n",
    "    sampling<-setNames(data.frame(matrix(ncol = 3, nrow = 0)), c(\"Sites\", \"samples\", \"total\"))\n",
    "    for (c in 1:length(unique(dms$meta$analyses[,analysis]))) {\n",
    "        for (ind in 1:samplethreshold) {\n",
    "            sampling[nrow(sampling) + 1,] = list(c,ind,c*ind)\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    ###this bit orders the sampling strategy and removes strategies with less than x samples\n",
    "    sampling<-sampling[order(sampling$total),]\n",
    "    # sampling<-sampling[which(sampling$total>=samplethreshold),] #this reduces sampling to 5 samples per site\n",
    "    sampling<-sampling[which(sampling$Sites<=20),] # this reduces sampling to 20 Sites.\n",
    "\n",
    "    ###N_t_vec is the total number of individuals to be sampled (i.e. the horizontal axis of the output plot)\n",
    "    N_t_vec  <- unique(sampling$total)\n",
    "    sampling <- sampling[which(sampling$total %in% N_t_vec),]\n",
    "\n",
    "    ###script randomly selects selected number of Sites, ###and in each site a number of samples\n",
    "    dms_meta <- cbind.data.frame(sample=dms$meta$sample_names, site=dms$meta$analyses[,analysis],lat=dms$meta$lat, long=dms$meta$long)\n",
    "    colnames(dms_meta) <- c(\"sample\",\"site\",\"lat\",\"long\")\n",
    "    unique_Sites <- unique(na.omit(dms_meta$site)) #maximum number of Sites\n",
    "    gvals <- list() #accumulate data to be saved #samples & Sites to choose, number of common alleles\n",
    "\n",
    "    OGM_DF<-setNames(data.frame(matrix(ncol = 9, nrow = 0)), c(\"m\",\"t_num_indv\", \"n_Sites_sel\", \"n_indiv_sel\", \"combined\", \"rand_Sites_sel\", \n",
    "                                                             \"rand_indiv_sel\", \"jvals\", \"Aprop\"))\n",
    "    set.seed(12345)\n",
    "\n",
    "    for (n in 1:length(sampling$Sites)) {\n",
    "    \n",
    "        n_Sites_sel <- sampling$Sites[n]\n",
    "        n_indiv_sel <- sampling$samples[n]\n",
    "        combined <- paste0(n_Sites_sel, \" \", n_indiv_sel) \n",
    "        t_num_indv <- n_Sites_sel*n_indiv_sel\n",
    "     \n",
    "        for (m in 1:1000) {   \n",
    "            rand_Sites_sel <- unique_Sites[sample(1:length(unique_Sites))[1:n_Sites_sel]]; #print(rand_Sites_sel)  \n",
    "            rand_indiv_sel <- c()\n",
    "            for (s in 1:n_Sites_sel) {\n",
    "                rand_indiv <- as.character(dms_meta$sample[which(dms_meta$site == rand_Sites_sel[s])][sample(1:length(which(dms_meta$site == rand_Sites_sel[s])))[1:n_indiv_sel]])\n",
    "                rand_indiv_sel <- c(rand_indiv_sel,rand_indiv) ; #print(rand_indiv_sel)\n",
    "            }\n",
    "      \n",
    "            # dms_meta$site[which(dms_meta$sample %in% rand_indiv_sel)]\n",
    "            fixed_indi <- which(dms$sample_names %in% rand_indiv_sel)\n",
    "            ran_vec <- rep(0, nrow(gt_sw_comp))\n",
    "            ran_vec[fixed_indi] <- 1\n",
    "            common_alleles  <- common_allele_count(gt_sw_comp, ran_vec)\n",
    "            sw_maf    <- get_maf(gt_sw_comp)\n",
    "            threshold_maf <- thresh_maf #change to higher if singleton is stronger possibility e.g Cattai\n",
    "            #common allel count is 1, minor allele count observed once\n",
    "            i_sw_common <- which(sw_maf > threshold_maf)\n",
    "            jvals <- length( intersect( which(common_alleles[[2]] > 0), i_sw_common))\n",
    "            Aprop<-jvals/length(i_sw_common)\n",
    "            gvals[[m]] <- data.frame(m,t_num_indv,n_Sites_sel,n_indiv_sel,combined,rand_Sites_sel,rand_indiv_sel,jvals, Aprop) \n",
    "        }\n",
    "\n",
    "        #save big_data2 somewhere...\n",
    "        big_data2 = do.call(rbind, gvals)\n",
    "        write.csv(big_data2, file = paste0(subDir,\"randomisation_\",n_Sites_sel,\"Sites_\",n_indiv_sel,\"individuals.csv\"), row.names = FALSE)\n",
    "        OGM_DF<-rbind(OGM_DF, big_data2) \n",
    "    }\n",
    "  \n",
    "    clean_data <- OGM_DF %>% group_by(t_num_indv,n_Sites_sel,combined, m) %>% dplyr::summarize(Allele=mean(Aprop),Allelen=mean(jvals), samples=n()) %>% data.frame        \n",
    "    clean_data$t_num_indv<-as.numeric(clean_data$t_num_indv)\n",
    "    write.csv(clean_data, file = paste0(subDir, \"sampling_randomisation_summary.csv\"), row.names = FALSE)\n",
    "    #If already run sampling randomisation use line below\n",
    "    #clean_data<-read.csv(file = paste0(\"sampling_randomisation_summary.csv\"), sep = \",\")\n",
    "\n",
    "   \n",
    "   \n",
    "    #claculate mininunm and maximum alleleprop for each sampling strategy\n",
    "\n",
    "    for (e in unique(clean_data$combined)){\n",
    "    min_alleledf <- min(clean_data$Allele[which(clean_data$combined==e)])\n",
    "    clean_data$min_allele[which(clean_data$combined==e)] = min_alleledf\n",
    "    max_alleledf <- max(clean_data$Allele[which(clean_data$combined==e)])\n",
    "    clean_data$max_allele[which(clean_data$combined==e)] = max_alleledf\n",
    "        }\n",
    "\n",
    "    write.csv(clean_data, file = paste0(subDir, \"sampling_randomisation_summary.csv\"), row.names = FALSE)\n",
    "\n",
    "\n",
    "#reorder clean_data and deteimine the first sampling combination which completely reaches over 0.9 alleleprop\n",
    "clean_data <- clean_data[order(clean_data$n_Sites_sel, clean_data$t_num_indv),]\n",
    "firstcombonumber <- which(clean_data$min_allele > 0.9)[1]\n",
    "combointercept <- interaction(clean_data$n_Sites_sel, clean_data$t_num_indv)[firstcombonumber]\n",
    "\n",
    "\n",
    "#plot a lineplot representing alleleprop vs sampling strategies\n",
    "    OGM_boxplot <- ggplot(clean_data, aes(x=interaction(n_Sites_sel,t_num_indv), y=Allele)) + \n",
    "    geom_segment(data=clean_data, aes(x=interaction(n_Sites_sel,t_num_indv), y=min_allele, xend=interaction(n_Sites_sel,t_num_indv), yend=max_allele), size=5, position =  position_dodge(width = 1, preserve = \"total\"))+ \n",
    "    gghighlight(min(Allele) > 0.9, label_key = n_Sites_sel) +\n",
    "    geom_vline(xintercept = combointercept, linetype=\"solid\", linewidth=5, alpha=0.5, colour=\"darkgreen\")+     \n",
    "    geom_boxplot(data=clean_data,aes(x=interaction(n_Sites_sel,t_num_indv), y=min_allele), color=\"blue\") +\n",
    "    geom_boxplot(data=clean_data, aes(x=interaction(n_Sites_sel,t_num_indv), y=max_allele), color=\"red\")+\n",
    "    scale_x_discrete(guide = \"axis_nested\")+\n",
    "     coord_cartesian(expand = FALSE)+\n",
    "        scale_fill_continuous() +\n",
    "        theme_bw() + scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1))+\n",
    "        labs(title=paste0(species,\" sampling strategy\"), subtitle = paste0(\"1000 Randomisations, limiting \", samplethreshold, \" samples from every pop\"), y=\"Allele Proportion\", x=\"Number of sites \\n Total samples across all sites\")+\n",
    "        geom_hline(yintercept = 0.9, linetype=\"dashed\", alpha=1, colour=\"red\")+\n",
    "        #geom_segment(aes(x=combointercept, y= 0, xend=combointercept, yend=0.9), size=5, color=\"green\")+\n",
    "        theme(panel.spacing=unit(1,\"lines\"),\n",
    "        strip.background=element_rect(color=\"grey30\", fill=\"grey90\"),\n",
    "        panel.grid = element_blank())\n",
    "ggsave(OGM_boxplot, file=paste0(subDir, species,\"Sampling_Strategy_LinePlot2.png\"), width = 20, height = 10, dpi = 300, units = \"in\", device='png')\n",
    "\n",
    "\n",
    "\n",
    "    #read sampling combination file and select the lowest site and individual combinations for which all 100 reps are over the threshold value\n",
    "    allelepropsum <- read.csv(paste0(subDir, \"sampling_randomisation_summary.csv\"))\n",
    "\n",
    "    subDir <-paste0(outputloc2, \"OptSiteMix/\")\n",
    "    if(!dir.exists(file.path(subDir))){\n",
    "    \n",
    "        dir.create(file.path(subDir))\n",
    "    }\n",
    "  \n",
    "    threshlist <- allelepropsum %>% filter(allelepropsum$Allele>samplingthreshold)\n",
    "    vals <- unique(threshlist$combined)\n",
    "    countvals <- c()\n",
    "    for (v in 1:length(vals)){  \n",
    "        countvals[[v]] <- sum(threshlist$combined==vals[v]) \n",
    "        if (countvals[[v]]==100){ \n",
    "            threshlist <- threshlist \n",
    "        } else { #print(\"removing from df\")\n",
    "            threshlist <- threshlist %>% filter(threshlist$combined!=vals[v])}    \n",
    "    } \n",
    "\n",
    "    colnames(threshlist) <- c(\"total_indv\",\"num_Sites\",\"combined\",\"m\", \"allele\", \"num_alele\", \"samples\")\n",
    "    write.csv(threshlist, file = paste0(subDir,\"List of sampling combos with every combination over \", samplingthreshold, \"threshold.csv\"), row.names = TRUE)\n",
    "\n",
    "    orderbylowestsite <- threshlist[order(threshlist$num_Sites,threshlist$total_indv),]\n",
    "    an <- orderbylowestsite$num_Sites[1]\n",
    "    bn <- orderbylowestsite$total_indv[1]\n",
    "    anbn <- cbind(an, bn)\n",
    "\n",
    "    orderbylowestnum_indv <- threshlist[order(threshlist$total_indv, threshlist$num_Sites),]\n",
    "    cn <- orderbylowestnum_indv$num_Sites[1]\n",
    "    dn <- orderbylowestnum_indv$total_indv[1]\n",
    "    cndn <- cbind(cn, dn)\n",
    "\n",
    "    site_num_df <- rbind(anbn, cndn)\n",
    "    colnames(site_num_df) <- c(\"Number of Sites\", \"Number of Total Samples\")\n",
    "    rownames(site_num_df) <- c(paste0(\"Minimum Site Combination Over \",samplingthreshold,\"%\"), paste0(\"Minimum Sample Combination Over \",samplingthreshold,\"%\"))\n",
    "\n",
    "    write.csv(site_num_df, file = paste0(subDir,\"Final Site Combinations for \", samplingthreshold, \"threshold.csv\"), row.names = TRUE)\n",
    "\n",
    "    print(paste0(\"AlleleProp analysis for \",species,\" \", analysis, \" complete\"))\n",
    "\n",
    "\n",
    "\n",
    "#     ██████╗ ██████╗ ████████╗███████╗██╗████████╗███████╗███╗   ███╗██╗██╗  ██╗    ███████╗██╗████████╗███████╗███████╗\n",
    "#    ██╔═══██╗██╔══██╗╚══██╔══╝██╔════╝██║╚══██╔══╝██╔════╝████╗ ████║██║╚██╗██╔╝    ██╔════╝██║╚══██╔══╝██╔════╝██╔════╝\n",
    "#    ██║   ██║██████╔╝   ██║   ███████╗██║   ██║   █████╗  ██╔████╔██║██║ ╚███╔╝     ███████╗██║   ██║   █████╗  ███████╗\n",
    "#    ██║   ██║██╔═══╝    ██║   ╚════██║██║   ██║   ██╔══╝  ██║╚██╔╝██║██║ ██╔██╗     ╚════██║██║   ██║   ██╔══╝  ╚════██║\n",
    "#    ╚██████╔╝██║        ██║   ███████║██║   ██║   ███████╗██║ ╚═╝ ██║██║██╔╝ ██╗    ███████║██║   ██║   ███████╗███████║\n",
    "#     ╚═════╝ ╚═╝        ╚═╝   ╚══════╝╚═╝   ╚═╝   ╚══════╝╚═╝     ╚═╝╚═╝╚═╝  ╚═╝    ╚══════╝╚═╝   ╚═╝   ╚══════╝╚══════╝\n",
    "                                                                                                                                                            \n",
    "  \n",
    "  \n",
    "    #Now check from the paratmeters file to see if the user wants minimise the number of Sites, and/or minimise the total number of individuals \n",
    "    #and run the OptSiteMix for the reauested parameters\n",
    "\n",
    "  \n",
    "    if ((OptSiteMixMinSites == 'yes') == TRUE |(OptSiteMixMinSites == 'Yes') == TRUE |(OptSiteMixMinSites == 'Y') == TRUE){ \n",
    "        print(\"Running OptSiteMix for minimum Sites\")\n",
    "        subDir <-paste0(outputloc2, \"OptSiteMix/Minimum_Sites/\")\n",
    "        if(!dir.exists(file.path(subDir))){\n",
    "            dir.create(file.path(subDir))\n",
    "        }\n",
    "    \n",
    "        gta  <- dms$gt\n",
    "        pops <- as.vector(na.omit(dms$meta$analyses[,analysis]))    \n",
    "        tmpmac <- gt_to_pop_minor_allele_counts(gta, pops)  \n",
    "\n",
    "        if (any(which(colSums(tmpmac$N < 2)>0)) == TRUE | any(which(colSums(tmpmac$MAC == 0)==nrow(tmpmac$MAC))) == TRUE) {\n",
    "            i_loc_miss <- which(colSums(tmpmac$N < 2)>0)\n",
    "            i_mac_zero <- which(colSums(tmpmac$MAC == 0)==nrow(tmpmac$MAC))\n",
    "            i_rm <- union(i_loc_miss, i_mac_zero)\n",
    "            gta <- gta[, -i_rm]  \n",
    "            pmac <- gt_to_pop_minor_allele_counts(gta, pops)\n",
    "        } else {\n",
    "            pmac <- gt_to_pop_minor_allele_counts(gta, pops)\n",
    "        }\n",
    "    \n",
    "    \n",
    "        uq <- length(unique(pops)) \n",
    "        opt_psfs_MAC <- list()               \n",
    "        minw <- rep(0, uq)\n",
    "\n",
    "        for ( m in 1:length(an) ) {\n",
    "            N_t <- as.numeric(an[m])\n",
    "            cat(\"\\n Running \", N_t, \" ...\\n\") \n",
    "            max_wts <- rep(1, uq)\n",
    "            f <- uq-N_t\n",
    "            initial_wts <- sample(c(rep(1,N_t),rep(0, f)))\n",
    "            #N_t_MACvar <- paste0(\"opt_psfs_MAC_\", N_t)\n",
    "            opt_psfs_MAC[[m]] <- optimize_single_objective( gt=pmac$MAC, N_t=N_t, initial_weights=initial_wts, weights_max=max_wts, measure=\"psfs\", max_steps=num_steps, max_t=0.005, m=20, p_depends_delta=TRUE, pMAC_mode=TRUE, Nmat=pmac$N, weights_min=minw)\n",
    "            png(file = paste0(subDir, species, analysis,\"optpsfs_minSites_MAC_temperature_\", N_t, \"_Sites.png\"), width = 13.3, height = 7.5, res = 600, units = \"in\") \n",
    "            plot(opt_psfs_MAC[[m]]$value)         \n",
    "            dev.off()    \n",
    "\n",
    "            if (length(an) >1){   \n",
    "                ### Generate table of optimised site selection\n",
    "                solution_table_site <- mat.or.vec(nrow(pmac$MAC), length(an))\n",
    "                for (i in 1:length(an)) {\n",
    "                    solution_table_site[,i] <- cbind(opt_psfs_MAC[[i]]$weight[num_steps,])            \n",
    "                }\n",
    "            }else{\n",
    "                solution_table_site = NULL\n",
    "                for (i in 1:length(an)) {\n",
    "                    solution_table_site <- as.data.frame(cbind(opt_psfs_MAC[[i]]$weight[num_steps,]))\n",
    "                }\n",
    "            }   \n",
    "      \n",
    "            colnames(solution_table_site) <- paste0(\"Sites\")\n",
    "            rownames(solution_table_site) <- rownames(pmac$MAC)     \n",
    "            write.table(solution_table_site, paste0(subDir, species, analysis,\" ogmsfs min Sites.csv\"),sep=\",\",quote=FALSE, row.name=TRUE,col.name=TRUE)\n",
    "            \n",
    "            #plot optimised site selection\n",
    "            Opt_solution_pdf <- c() \n",
    "            for (ib in 1:length(an)) {\n",
    "                Opt_solution_pdf[ib] <- opt_psfs_MAC[[ib]]$value[num_steps]\n",
    "            }\n",
    "      \n",
    "      \n",
    "            Opt_solution_pdffinal <- as.data.frame(cbind(paste0(\"Sites\"), Opt_solution_pdf))\n",
    "            colnames(Opt_solution_pdffinal) <- c(\"Sites\", \"sfs_prop_m\")\n",
    "            Opt_Solution_Final <- as.data.frame(lapply(Opt_solution_pdffinal, unlist))\n",
    "            Opt_Solution_Final$sfs_prop_m <- as.numeric(Opt_Solution_Final$sfs_prop_m)\n",
    "            Opt_Solution_Final$Sites <- fct_inorder(Opt_Solution_Final$Sites)\n",
    "            opt_solution_dotplot <- ggplot(Opt_Solution_Final, aes(x=Sites, y=sfs_prop_m)) + geom_dotplot(binaxis='y', binwidth=0.005, stackdir='center') + labs(y=\"SFS Proportion m\", x=\"Sites\")\n",
    "            opt_solution_dotplot\n",
    "            ### Randomisation script - generates randomised site selection to compare to optimised site selection\n",
    "            rand_results <- c()\n",
    "            solution_pdf <- c()\n",
    "            rand_results_val <- c()\n",
    "\n",
    "            for ( ic in 1:length(an) ) {   \n",
    "        \n",
    "                iNt <- as.numeric(an[ic])    \n",
    "        \n",
    "                for (j in 1:rand_numsteps) {      \n",
    "                    f <- uq-iNt       \n",
    "                    initial_wts <- sample(c(rep(1,iNt),rep(0, f)))   \n",
    "                    RandomSites <- sample(1:uq)[1:iNt]\n",
    "                    rand_minw <- rep(0, uq)\n",
    "                    rand_minw[RandomSites] = 1\n",
    "                    rand_results[[j]] <- optimize_single_objective( gt=pmac$MAC, N_t=iNt, initial_weights=initial_wts, weights_max=max_wts, measure=\"psfs\", max_steps=1, max_t=0.005, m=20, p_depends_delta=TRUE, pMAC_mode=TRUE, Nmat=pmac$N, weights_min=rand_minw)\n",
    "                    rand_results_val[j] <- as.data.frame(rand_results[[j]]$value)\n",
    "                }\n",
    "                rand_results_valfinal <- cbind((paste0(\"Sites\")), rand_results_val)\n",
    "                solution_pdf <- as.data.frame(rbind(solution_pdf, rand_results_valfinal))\n",
    "            }\n",
    "      \n",
    "            colnames(solution_pdf) <- c(\"Sites\", \"sfs_prop_m\")\n",
    "            solution_pdf2 <- as.data.frame(lapply(solution_pdf, unlist))\n",
    "            solution_pdf2$Sites <- fct_inorder(solution_pdf2$Sites)\n",
    "            rand_solution_plot <- ggplot(solution_pdf2, aes(x=Sites, y=sfs_prop_m))+ geom_violin() + labs(y=\"SFS Proportion m\", x=\"Sites\")\n",
    "            write.table(solution_pdf2, paste0(subDir, species, analysis,\" min Sites Randomisation Table.csv\"),sep=\",\",quote=FALSE, row.name=FALSE,col.name=TRUE)\n",
    "            write.table(Opt_Solution_Final, paste0(subDir, species, analysis,\" Optimised min Sites Table.csv\"),sep=\",\",quote=FALSE, row.name=FALSE,col.name=TRUE)\n",
    "\n",
    "            ### Combined plot of optimised vs randomised site selection\n",
    "            combined_plot <- ggplot(solution_pdf2, aes(x=Sites, y=sfs_prop_m)) + \n",
    "            geom_violin() + \n",
    "            geom_dotplot(data=Opt_Solution_Final, binaxis='y', binwidth=0.005, stackdir='center', fill=\"red\") + \n",
    "            labs(title=paste0(\"Optimised vs Random for \", iNt, \"Sites\"), subtitle= paste0(species,\" \", analysis), y=\"SFS Proportion (m)\", x=\"Sites Selected (n)\") + \n",
    "            theme_minimal(base_size=20) + \n",
    "            theme(axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 0, l = 0)),  plot.title = element_text(margin = margin(t = 0, r = 0, b = 10, l = 0)), plot.subtitle = element_text(margin = margin(t = 0, r = 0, b = 20, l = 0)))    \n",
    "            combined_plot\n",
    "            ggsave(paste0(species, analysis,\" optimised min Sites VS random.pdf\"), path=paste0(subDir), width = 13, height = 12, dpi = 600, units = \"in\")\n",
    "\n",
    "            #Now take the optimised site combination and input these as forced allele proportion Sites \n",
    "            #to compare between optimised vs random allele proportion      \n",
    "            solution_table_site$row_names <- row.names(solution_table_site)\n",
    "            OrderforOptimisedSites <- solution_table_site[order(solution_table_site$Sites, decreasing =TRUE),]\n",
    "            OptimisedSites <- OrderforOptimisedSites$row_names[1:an]\n",
    "\n",
    "            ###if you want to remove all missingness (recommended sometimes use the first hashed out section. otherwise use the second)\n",
    "            #cones GT matrix in new variable (ColID are SNPIDs)               \n",
    "            #create a temp meta dataframe to remove Sites/samples that include less than X individuals\n",
    "            temp<-as.data.frame(m1$analyses)\n",
    "            # Below lines remove Sites with less than threshold number of samples, and subsample Sites that are above the threshold  \n",
    "            samplethreshold <-5 # chnage this to what number of samples you want toi have uniform across all pops  \n",
    "            for (x in unique(na.omit(temp[,analysis]))) {     \n",
    "                pop_samples <- which(temp[,analysis] == x)    \n",
    "                if (length(pop_samples) < samplethreshold) {     \n",
    "                    temp[, analysis]<-gsub(x, replacement=NA, temp[, analysis])      \n",
    "                    #print(paste0(\"Removing \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))    \n",
    "                }    \n",
    "                if (length(pop_samples) == samplethreshold) {      \n",
    "                    #print(paste0(\"Keeping \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))    \n",
    "                }    \n",
    "                if (length(pop_samples) > samplethreshold) {      \n",
    "                    subsamplepops <- pop_samples[sample(1:length(pop_samples), size=samplethreshold, replace = F)]      \n",
    "                    for (b in 1:length(pop_samples)){        \n",
    "                        if (pop_samples[b] %in% subsamplepops == FALSE){          \n",
    "                            temp[, analysis][pop_samples[b]] <- NA          \n",
    "                        }        \n",
    "                        #print(paste0(\"Reducing \",x, \" to a sample size of \", samplethreshold,\" samples\"))      \n",
    "                    }    \n",
    "                } else {}  \n",
    "            }               \n",
    "        \n",
    "            m1$analyses<-temp      \n",
    "            dm <- dart.meta.data.merge(d3, m1)      \n",
    "            fields    <- c(analysis)      \n",
    "            dms     <- data.by.meta.fields(dm, fields, RandRbase, species, dataset, object=analysis); #print(dms$meta$analyses[,analysis])     \n",
    "            #correct inconsistencies in J's scripts for naming treatment which is for naming files\n",
    "            treatment <- paste0(\"raw_SNPFilt_1SNPperClone_Field_\", analysis)         \n",
    "            dms$treatment <- treatment         \n",
    "            gta <- dms$gt             \n",
    "            gt_sw_comp <- gta    \n",
    "            ncol(gt_sw_comp)    \n",
    "\n",
    "            ###load required code\n",
    "            source_url(\"https://github.com/RichardDimon/get_maf/blob/main/get_maf.r?raw=TRUE\")\n",
    "            source_url(\"https://github.com/RichardDimon/common_allele_count/blob/main/common_allele_count.r?raw=TRUE\")\n",
    "            ###the next line of code runs a loop that create a table with all \n",
    "            ###possible combinations of sampling assuming all included pops have atleast 5 samples available\n",
    "            sampling<-setNames(data.frame(matrix(ncol = 3, nrow = 0)), c(\"Sites\", \"samples\", \"total\"))\n",
    "            for (c in 1:length(unique(dms$meta$analyses[,analysis]))) { \n",
    "                for (ind in 1:samplethreshold) {\n",
    "                    sampling[nrow(sampling) + 1,] = list(c,ind,c*ind) \n",
    "                }\n",
    "            }\n",
    "      \n",
    "            ###this bit orders the sampling strategy and removes strategies with less than x samples\n",
    "            sampling<-sampling[order(sampling$total),]\n",
    "            ###script randomly selects selected number of Sites and in each site a number of samples\n",
    "            dms_meta <- cbind.data.frame(sample=dms$meta$sample_names, site=dms$meta$analyses[,analysis],lat=dms$meta$lat, long=dms$meta$long)\n",
    "            colnames(dms_meta) <- c(\"sample\",\"site\",\"lat\",\"long\")\n",
    "            unique_Sites <- unique(na.omit(dms_meta$site)) #maximum number of Sites\n",
    "            gvals <- list() #accumulate data to be saved #samples & Sites to choose, number of common alleles\n",
    "\n",
    "            #insert loop here to run through table listing parameters in bottom two lines#\n",
    "            OGM_DF<-setNames(data.frame(matrix(ncol = 8, nrow = 0)), c(\"m\",\"t_num_indv\", \"n_Sites_sel\", \"n_indiv_sel\", \"rand_Sites_sel\", \n",
    "                                                             \"rand_indiv_sel\", \"jvals\", \"Aprop\"))\n",
    "            set.seed(12345)   \n",
    "            ###Set Sites to select by name and set numbers of Sites and individuals to select###\n",
    "            Sites_sel <- OptimisedSites\n",
    "            #Sites_sel <- unique(na.omit(dms_meta$site))       \n",
    "            rand_indiv_sel <- c()\n",
    "            n_Sites_sel <- as.numeric(an)\n",
    "            t_num_indv <- as.numeric(bn)\n",
    "            n_indiv_sel <- t_num_indv/n_Sites_sel         \n",
    "\n",
    "            for (m in 1:1000) {\n",
    "                rand_Sites_sel <- Sites_sel[sample(1:length(Sites_sel))[1:n_Sites_sel]]; #print(rand_Sites_sel)  \n",
    "                rand_indiv_sel <- c()      \n",
    "                for (s in 1:n_Sites_sel) {    \n",
    "                    rand_indiv <- as.character(dms_meta$sample[which(dms_meta$site == rand_Sites_sel[s])][sample(1:length(which(dms_meta$site == rand_Sites_sel[s])))[1:n_indiv_sel]])     \n",
    "                    rand_indiv_sel <- c(rand_indiv_sel,rand_indiv) ; #print(rand_indiv_sel)  \n",
    "                }    \n",
    "        \n",
    "       \n",
    "                # dms_meta$site[which(dms_meta$sample %in% rand_indiv_sel)]\n",
    "                fixed_indi <- which(dms$sample_names %in% rand_indiv_sel)      \n",
    "                ran_vec <- rep(0, nrow(gt_sw_comp))  \n",
    "                ran_vec[fixed_indi] <- 1 \n",
    "                common_alleles  <- common_allele_count(gt_sw_comp, ran_vec)     \n",
    "                sw_maf    <- get_maf(gt_sw_comp) \n",
    "                threshold_maf <- thresh_maf #change to higher if singleton is stronger possibility e.g Cattai   \n",
    "                #common allel count is 1, minor allele count observed once  \n",
    "                i_sw_common <- which(sw_maf > threshold_maf)  \n",
    "                jvals <- length( intersect( which(common_alleles[[2]] > 0), i_sw_common))   \n",
    "                Aprop<-jvals/length(i_sw_common)       \n",
    "                gvals[[m]] <- data.frame(m,t_num_indv,n_Sites_sel,n_indiv_sel,rand_Sites_sel,rand_indiv_sel,jvals, Aprop) \n",
    "            }\n",
    "      \n",
    "      \n",
    "            #save big_data2 somewhere... \n",
    "            big_data2 = do.call(rbind, gvals)\n",
    "            write.csv(big_data2, file = paste0(subDir,\"forced\",n_Sites_sel,\"Sites_\",n_indiv_sel,\"individuals.csv\"), row.names = FALSE) \n",
    "            OGM_DF<-rbind(OGM_DF, big_data2)\n",
    "            clean_data_optimised <- OGM_DF %>% group_by(t_num_indv,n_Sites_sel,m) %>% summarize(Average_Allele=mean(Aprop),Average_Allelen=mean(jvals)) %>% data.frame\n",
    "            #clean_data$t_num_indv<-as.numeric(clean_data$t_num_indv)\n",
    "            write.csv(clean_data_optimised, file = paste0(subDir, \"Optimised_AlleleProp_Summary.csv\"), row.names = FALSE)\n",
    "\n",
    "            #Now repreat the same using randomisation of all Sites within the dataset (not just the selected forced Sites)\n",
    "            Sites_sel <- unique(na.omit(dms_meta$site))      \n",
    "            rand_indiv_sel <- c()\n",
    "\n",
    "            for (m in 1:1000) {\n",
    "                rand_Sites_sel <- Sites_sel[sample(1:length(Sites_sel))[1:n_Sites_sel]]; #print(rand_Sites_sel)\n",
    "                rand_indiv_sel <- c()          \n",
    "                for (s in 1:n_Sites_sel) {    \n",
    "                    rand_indiv <- as.character(dms_meta$sample[which(dms_meta$site == rand_Sites_sel[s])][sample(1:length(which(dms_meta$site == rand_Sites_sel[s])))[1:n_indiv_sel]])   \n",
    "                    rand_indiv_sel <- c(rand_indiv_sel,rand_indiv) ; #print(rand_indiv_sel)  \n",
    "                }    \n",
    "\n",
    "                # dms_meta$site[which(dms_meta$sample %in% rand_indiv_sel)]   \n",
    "                fixed_indi <- which(dms$sample_names %in% rand_indiv_sel)     \n",
    "                ran_vec <- rep(0, nrow(gt_sw_comp))   \n",
    "                ran_vec[fixed_indi] <- 1   \n",
    "                common_alleles  <- common_allele_count(gt_sw_comp, ran_vec)       \n",
    "                sw_maf    <- get_maf(gt_sw_comp)   \n",
    "                threshold_maf <- thresh_maf #change to higher if singleton is stronger possibility e.g Cattai  \n",
    "                #common allel count is 1, minor allele count observed once  \n",
    "                i_sw_common <- which(sw_maf > threshold_maf)  \n",
    "                jvals <- length( intersect( which(common_alleles[[2]] > 0), i_sw_common))  \n",
    "                Aprop<-jvals/length(i_sw_common)       \n",
    "                gvals[[m]] <- data.frame(m,t_num_indv,n_Sites_sel,n_indiv_sel,rand_Sites_sel,rand_indiv_sel,jvals, Aprop) \n",
    "            }  \n",
    "      \n",
    "      \n",
    "            #save big_data2 somewhere...\n",
    "            big_data2 = do.call(rbind, gvals)\n",
    "            write.csv(big_data2, file = paste0(subDir,\"randomisation_\",n_Sites_sel,\"Sites_\",n_indiv_sel,\"individuals.csv\"), row.names = FALSE)\n",
    "            OGM_DF<-rbind(OGM_DF, big_data2)\n",
    "            clean_data_random <- OGM_DF %>% group_by(t_num_indv,n_Sites_sel,m) %>% summarize(Average_Allele=mean(Aprop),Average_Allelen=mean(jvals)) %>% data.frame\n",
    "            #clean_data$t_num_indv<-as.numeric(clean_data$t_num_indv)\n",
    "            write.csv(clean_data_random, file = paste0(subDir, \"Random_AlleleProp_Summary.csv\"), row.names = FALSE)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        }\n",
    "            \n",
    "        #FORCED SITE Optimisation\n",
    "        if ((ForcedOptSiteMix == 'yes') == TRUE |(ForcedOptSiteMix == 'Yes') == TRUE |(ForcedOptSiteMix == 'Y') == TRUE ){\n",
    "            #reads the string variable from the parameters file and forced optimisation selection in the binary format for minw\n",
    "            ForcedOptSites <- str_split(ListForcedSites, \",\", simplify=TRUE);\n",
    "            uqpops <- unique(pops)\n",
    "            \n",
    "            #force site number and total samples if required below:\n",
    "            #n <- 3\n",
    "            #n <-5\n",
    "            \n",
    "            if (length(ForcedOptSites) > an) {\n",
    "                print(paste0(\"Warning: too many forced sites! need to supply \", an, \" or fewer sites\"))\n",
    "            } else { \n",
    "                for (p in 1:length(ForcedOptSites)){\n",
    "                    uqpops <- gsub(ForcedOptSites[p], \"1\", uqpops)\n",
    "                }\n",
    "                for (v in 1:length(uqpops)){\n",
    "                    if (uqpops[v] != 1){\n",
    "                        uqpops <- gsub(uqpops[v], \"0\", uqpops)\n",
    "                    } else {}    \n",
    "                }\n",
    "                minw <- uqpops\n",
    "                print(\"Running Forced OptSiteMix for minimum sites\")        \n",
    "                subDir <-paste0(outputloc2, \"OptSiteMix/Minimum_Sites/ForcedSiteSelection/\")\n",
    "                if(!dir.exists(file.path(subDir))){\n",
    "                    dir.create(file.path(subDir))\n",
    "                }\n",
    "\n",
    "\n",
    "                gta  <- dms$gt\n",
    "                pops <- as.vector(na.omit(dms$meta$analyses[,analysis]))    \n",
    "                tmpmac <- gt_to_pop_minor_allele_counts(gta, pops)    \n",
    "\n",
    "                if (any(which(colSums(tmpmac$N < 2)>0)) == TRUE | any(which(colSums(tmpmac$MAC == 0)==nrow(tmpmac$MAC))) == TRUE) {\n",
    "                    i_loc_miss <- which(colSums(tmpmac$N < 2)>0)\n",
    "                    i_mac_zero <- which(colSums(tmpmac$MAC == 0)==nrow(tmpmac$MAC))\n",
    "                    i_rm <- union(i_loc_miss, i_mac_zero)\n",
    "                    gta <- gta[, -i_rm]  \n",
    "                    pmac <- gt_to_pop_minor_allele_counts(gta, pops)\n",
    "                } else {\n",
    "                    pmac <- gt_to_pop_minor_allele_counts(gta, pops)\n",
    "                }\n",
    "\n",
    "                uq <- length(unique(pops)) \n",
    "                opt_psfs_MAC <- list()\n",
    "                print(\"running forced site selection...\")\n",
    "\n",
    "            }\n",
    "\n",
    "            for ( m in 1:length(an) ) {\n",
    "\n",
    "                N_t <- as.numeric(an[m])\n",
    "                cat(\"\\n Running \", N_t, \" ...\\n\")\n",
    "                max_wts <- rep(1, uq)\n",
    "                f <- uq-N_t\n",
    "                initial_wts <- sample(c(rep(1,N_t),rep(0, f)))\n",
    "                #N_t_MACvar <- paste0(\"opt_psfs_MAC_\", N_t)\n",
    "                opt_psfs_MAC[[m]] <- optimize_single_objective( gt=pmac$MAC, N_t=N_t, initial_weights=initial_wts, weights_max=max_wts, measure=\"psfs\", max_steps=num_steps, max_t=0.005, m=20, p_depends_delta=TRUE, pMAC_mode=TRUE, Nmat=pmac$N, weights_min=minw)       \n",
    "\n",
    "                png(file = paste0(subDir, species, analysis,\"optpsfs_minsites_MAC_temperature_\", N_t, \"_Forced_Sites.png\"), width = 13.3, height = 7.5, res = 600, units = \"in\")\n",
    "                plot(opt_psfs_MAC[[m]]$value)         \n",
    "                dev.off()\n",
    "\n",
    "                if (length(an) >1){   \n",
    "                    ### Generate table of optimised site selection\n",
    "                    solution_table_samp <- mat.or.vec(nrow(pmac$MAC), length(an))\n",
    "                    for (i in 1:length(an)) {\n",
    "                        solution_table_samp[,i] <- cbind(opt_psfs_MAC[[i]]$weight[num_steps,])        \n",
    "                    }\n",
    "                }else{\n",
    "                    solution_table_samp = NULL\n",
    "                    for (i in 1:length(an)) {   \n",
    "                        solution_table_samp <- as.data.frame(cbind(opt_psfs_MAC[[i]]$weight[num_steps,]))       \n",
    "                    }\n",
    "                }   \n",
    "\n",
    "                colnames(solution_table_samp) <- paste0(\"Sites\")\n",
    "                rownames(solution_table_samp) <- rownames(pmac$MAC)     \n",
    "                write.table(solution_table_samp, paste0(subDir, species, analysis,\" ogmsfs min sites\"),sep=\",\",quote=FALSE, row.name=TRUE,col.name=NA)\n",
    "\n",
    "                #plot optimised site selection\n",
    "                Opt_solution_pdf <- c() \n",
    "                for (ib in 1:length(an)) {\n",
    "\n",
    "                    Opt_solution_pdf[ib] <- opt_psfs_MAC[[ib]]$value[num_steps]\n",
    "                }\n",
    "\n",
    "\n",
    "                Opt_solution_pdffinal <- as.data.frame(cbind(paste0(\"Sites\"), Opt_solution_pdf))\n",
    "                colnames(Opt_solution_pdffinal) <- c(\"Sites\", \"sfs_prop_m\")\n",
    "                Opt_Solution_Final <- as.data.frame(lapply(Opt_solution_pdffinal, unlist))\n",
    "                Opt_Solution_Final$sfs_prop_m <- as.numeric(Opt_Solution_Final$sfs_prop_m)\n",
    "                Opt_Solution_Final$Sites <- fct_inorder(Opt_Solution_Final$Sites)\n",
    "                opt_solution_dotplot <- ggplot(Opt_Solution_Final, aes(x=Sites, y=sfs_prop_m)) + geom_dotplot(binaxis='y', binwidth=0.005, stackdir='center') + labs(y=\"SFS Proportion m\", x=\"Sites\")\n",
    "                opt_solution_dotplot\n",
    "\n",
    "                ### Randomisation script - generates randomised site selection to compare to optimised site selection\n",
    "                rand_results <- c()\n",
    "                solution_pdf <- c()\n",
    "                rand_results_val <- c()\n",
    "\n",
    "                for ( ic in 1:length(an) ) {\n",
    "\n",
    "                    iNt <- as.numeric(an[ic])\n",
    "                    for (j in 1:rand_numsteps) {\n",
    "                        f <- uq-iNt\n",
    "                        initial_wts <- sample(c(rep(1,iNt),rep(0, f)))\n",
    "                        RandomSites <- sample(1:uq)[1:iNt]\n",
    "                        rand_minw <- rep(0, uq)\n",
    "                        rand_minw[RandomSites] = 1\n",
    "                        rand_results[[j]] <- optimize_single_objective( gt=pmac$MAC, N_t=iNt, initial_weights=initial_wts, weights_max=max_wts, measure=\"psfs\", max_steps=1, max_t=0.005, m=20, p_depends_delta=TRUE, pMAC_mode=TRUE, Nmat=pmac$N, weights_min=rand_minw)\n",
    "                        rand_results_val[j] <- as.data.frame(rand_results[[j]]$value)    \n",
    "                    }\n",
    "                    rand_results_valfinal <- cbind((paste0(\"Sites\")), rand_results_val)\n",
    "                    solution_pdf <- as.data.frame(rbind(solution_pdf, rand_results_valfinal))\n",
    "                }\n",
    "\n",
    "\n",
    "                colnames(solution_pdf) <- c(\"Sites\", \"sfs_prop_m\")\n",
    "                solution_pdf2 <- as.data.frame(lapply(solution_pdf, unlist))\n",
    "                solution_pdf2$Sites <- fct_inorder(solution_pdf2$Sites)\n",
    "                rand_solution_plot <- ggplot(solution_pdf2, aes(x=Sites, y=sfs_prop_m))+ geom_violin() + labs(y=\"SFS Proportion m\", x=\"Sites\")\n",
    "\n",
    "                write.table(solution_pdf2, paste0(subDir, species, analysis,\" min sites Randomisation Table.csv\"),sep=\",\",quote=FALSE, row.name=FALSE,col.name=TRUE)\n",
    "                write.table(Opt_Solution_Final, paste0(subDir, species, analysis,\" Forced Optimised min sites Table.csv\"),sep=\",\",quote=FALSE, row.name=FALSE,col.name=TRUE)\n",
    "\n",
    "                ### Combined plot of optimised vs randomised site selection\n",
    "                combined_plot <- ggplot(solution_pdf2, aes(x=Sites, y=sfs_prop_m)) + \n",
    "                geom_violin() + \n",
    "                geom_dotplot(data=Opt_Solution_Final, binaxis='y', binwidth=0.005, stackdir='center', fill=\"red\") + \n",
    "                labs(title=paste0(\"Forced Optimised vs Random for \", iNt, \" Sites\"), subtitle= paste0(species,\" \", analysis), y=\"SFS Proportion (m)\", x=\"Sites Selected (n)\") + \n",
    "                theme_minimal(base_size=20) + \n",
    "                theme(axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 0, l = 0)),  plot.title = element_text(margin = margin(t = 0, r = 0, b = 10, l = 0)), plot.subtitle = element_text(margin = margin(t = 0, r = 0, b = 20, l = 0)))    \n",
    "                combined_plot\n",
    "                ggsave(paste0(species, analysis,\" forced optimised min sites VS random.pdf\"), path=paste0(subDir), width = 13, height = 12, dpi = 600, units = \"in\")  \n",
    "\n",
    "\n",
    "                #Now take the optimised site combination and input these as forced allele proportion Sites \n",
    "                #to compare between optimised vs random allele proportion      \n",
    "                solution_table_samp$row_names <- row.names(solution_table_samp)\n",
    "                OrderforforcedOptimisedSites <- solution_table_samp[order(solution_table_samp$Sites, decreasing =TRUE),]\n",
    "                forcedOptimisedSites <- OrderforforcedOptimisedSites$row_names[1:an]\n",
    "\n",
    "                #create a temp meta dataframe to remove Sites/samples that include less than X individuals\n",
    "                temp<-as.data.frame(m1$analyses)\n",
    "\n",
    "                # Below lines remove Sites with less than threshold number of samples, and subsample Sites that are above the threshold  \n",
    "                samplethreshold <-5 # chnage this to what number of samples you want toi have uniform across all pops  \n",
    "                for (x in unique(na.omit(temp[,analysis]))) {    \n",
    "                    pop_samples <- which(temp[,analysis] == x)    \n",
    "                    if (length(pop_samples) < samplethreshold) {     \n",
    "                        temp[, analysis]<-gsub(x, replacement=NA, temp[, analysis])      \n",
    "                        #print(paste0(\"Removing \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))    \n",
    "                    }    \n",
    "                    if (length(pop_samples) == samplethreshold) {      \n",
    "\n",
    "                        #print(paste0(\"Keeping \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))    \n",
    "                    }    \n",
    "                    if (length(pop_samples) > samplethreshold) {      \n",
    "                        subsamplepops <- pop_samples[sample(1:length(pop_samples), size=samplethreshold, replace = F)]      \n",
    "                        for (b in 1:length(pop_samples)){        \n",
    "                            if (pop_samples[b] %in% subsamplepops == FALSE){         \n",
    "                                temp[, analysis][pop_samples[b]] <- NA        \n",
    "                            }        \n",
    "                            #print(paste0(\"Reducing \",x, \" to a sample size of \", samplethreshold,\" samples\"))      \n",
    "                        }    \n",
    "                    } else {}    \n",
    "                }               \n",
    "\n",
    "                m1$analyses<-temp      \n",
    "                dm <- dart.meta.data.merge(d3, m1)      \n",
    "                fields    <- c(analysis)      \n",
    "                dms     <- data.by.meta.fields(dm, fields, RandRbase, species, dataset, object=analysis); #print(dms$meta$analyses[,analysis])     \n",
    "                #correct inconsistencies in J's scripts for naming treatment which is for naming files\n",
    "                treatment <- paste0(\"raw_SNPFilt_1SNPperClone_Field_\", analysis)         \n",
    "                dms$treatment <- treatment         \n",
    "                gta <- dms$gt             \n",
    "                gt_sw_comp <- gta    \n",
    "                ncol(gt_sw_comp) \n",
    "\n",
    "                ###load required code\n",
    "                source_url(\"https://github.com/RichardDimon/get_maf/blob/main/get_maf.r?raw=TRUE\")\n",
    "                source_url(\"https://github.com/RichardDimon/common_allele_count/blob/main/common_allele_count.r?raw=TRUE\")\n",
    "                ###the next line of code runs a loop that create a table with all \n",
    "                ###possible combinations of sampling assuming all included pops have atleast 5 samples available\n",
    "                sampling<-setNames(data.frame(matrix(ncol = 3, nrow = 0)), c(\"Sites\", \"samples\", \"total\"))\n",
    "                for (c in 1:length(unique(dms$meta$analyses[,analysis]))) { \n",
    "                    for (ind in 1:samplethreshold) {\n",
    "                        sampling[nrow(sampling) + 1,] = list(c,ind,c*ind) \n",
    "                    }\n",
    "                }\n",
    "                ###this bit orders the sampling strategy and removes strategies with less than x samples\n",
    "                sampling<-sampling[order(sampling$total),]\n",
    "                ###script randomly selects selected number of Sites and in each site a number of samples\n",
    "                dms_meta <- cbind.data.frame(sample=dms$meta$sample_names, site=dms$meta$analyses[,analysis],lat=dms$meta$lat, long=dms$meta$long)\n",
    "                colnames(dms_meta) <- c(\"sample\",\"site\",\"lat\",\"long\")\n",
    "                unique_Sites <- unique(na.omit(dms_meta$site)) #maximum number of Sites\n",
    "                gvals <- list() #accumulate data to be saved #samples & Sites to choose, number of common alleles\n",
    "\n",
    "                #insert loop here to run through table listing parameters in bottom two lines#\n",
    "                OGM_DF<-setNames(data.frame(matrix(ncol = 8, nrow = 0)), c(\"m\",\"t_num_indv\", \"n_Sites_sel\", \"n_indiv_sel\", \"rand_Sites_sel\", \n",
    "                \"rand_indiv_sel\", \"jvals\", \"Aprop\"))\n",
    "                set.seed(12345)   \n",
    "                ###Set Sites to select by name and set numbers of Sites and individuals to select###\n",
    "                Sites_sel <- forcedOptimisedSites\n",
    "                #Sites_sel <- unique(na.omit(dms_meta$site))       \n",
    "                rand_indiv_sel <- c()\n",
    "                n_Sites_sel <- as.numeric(an)\n",
    "                t_num_indv <- as.numeric(bn)\n",
    "                n_indiv_sel <- t_num_indv/n_Sites_sel         \n",
    "\n",
    "                for (m in 1:1000) {\n",
    "                    rand_Sites_sel <- Sites_sel[sample(1:length(Sites_sel))[1:n_Sites_sel]]; #print(rand_Sites_sel)  \n",
    "                    rand_indiv_sel <- c()      \n",
    "\n",
    "                    for (s in 1:n_Sites_sel) {    \n",
    "                        rand_indiv <- as.character(dms_meta$sample[which(dms_meta$site == rand_Sites_sel[s])][sample(1:length(which(dms_meta$site == rand_Sites_sel[s])))[1:n_indiv_sel]])     \n",
    "                        rand_indiv_sel <- c(rand_indiv_sel,rand_indiv) ; #print(rand_indiv_sel)  \n",
    "                    }    \n",
    "\n",
    "                        # dms_meta$site[which(dms_meta$sample %in% rand_indiv_sel)]\n",
    "                        fixed_indi <- which(dms$sample_names %in% rand_indiv_sel)      \n",
    "                        ran_vec <- rep(0, nrow(gt_sw_comp))  \n",
    "                        ran_vec[fixed_indi] <- 1 \n",
    "                        common_alleles  <- common_allele_count(gt_sw_comp, ran_vec)     \n",
    "                        sw_maf    <- get_maf(gt_sw_comp) \n",
    "                        threshold_maf <- thresh_maf #change to higher if singleton is stronger possibility e.g Cattai   \n",
    "                        #common allel count is 1, minor allele count observed once  \n",
    "                        i_sw_common <- which(sw_maf > threshold_maf)  \n",
    "                        jvals <- length( intersect( which(common_alleles[[2]] > 0), i_sw_common))   \n",
    "                        Aprop<-jvals/length(i_sw_common)       \n",
    "                        gvals[[m]] <- data.frame(m,t_num_indv,n_Sites_sel,n_indiv_sel,rand_Sites_sel,rand_indiv_sel,jvals, Aprop) \n",
    "                }\n",
    "\n",
    "\n",
    "                #save big_data2 somewhere... \n",
    "                big_data2 = do.call(rbind, gvals)\n",
    "                write.csv(big_data2, file = paste0(subDir,\"forced\",n_Sites_sel,\"Sites_\",n_indiv_sel,\"individuals.csv\"), row.names = FALSE) \n",
    "                OGM_DF<-rbind(OGM_DF, big_data2)\n",
    "                clean_data_forcedoptimised <- OGM_DF %>% group_by(t_num_indv,n_Sites_sel,m) %>% summarize(Average_Allele=mean(Aprop),Average_Allelen=mean(jvals)) %>% data.frame\n",
    "                #clean_data$t_num_indv<-as.numeric(clean_data$t_num_indv)\n",
    "                write.csv(clean_data_forcedoptimised, file = paste0(subDir, \"Forced_Optimisation_AlleleProp_Summary.csv\"), row.names = FALSE)\n",
    "\n",
    "\n",
    "\n",
    "                #now combine all results into a summmary csv file (with forced optimisation)                                         \n",
    "                final_output <- cbind.data.frame(analysis, \"Minimum Sites\", samplingthreshold, an, bn/an, bn, paste0(OptimisedSites, collapse=', '), clean_data_optimised$Average_Allele, clean_data_optimised$Average_Allelen, ListForcedSites, paste0(forcedOptimisedSites, collapse=', '), clean_data_forcedoptimised$Average_Allele, clean_data_forcedoptimised$Average_Allelen, clean_data_random$Average_Allele, clean_data_random$Average_Allelen)     \n",
    "                colnames(final_output) <- c(\"Analysis\", \"Selection\", \"Sample Threshold\", \"N Sites\",  \"N Samples per Site\", \"N Total Samples\", \"Optimised Sites\", \"Optimised Allele Prop\", \"Optimised N Alleles\", \"Intial Forced Sites\", \"Forced Optimised Sites\", \"Forced Optimised Allele Prop\", \"Forced Optimised N Alleles\", \"Random Allele Prop\", \"Random N Alleles\")        \n",
    "                subDir <-paste0(outputloc2, \"OptSiteMix/\")\n",
    "                write.csv(final_output, file = paste0(subDir, \"Forced_OptSiteMix_MinSites_Final_Output.csv\"), row.names= FALSE)   \n",
    "\n",
    "            }\n",
    "\n",
    "        } else {\n",
    "            #now combine all results into a summmary csv file                                          \n",
    "            final_output <- cbind.data.frame(analysis, \"Minimum Sites\", samplingthreshold, an, bn/an, bn, paste0(OptimisedSites, collapse=', '), clean_data_optimised$Average_Allele, clean_data_optimised$Average_Allelen, clean_data_random$Average_Allele, clean_data_random$Average_Allelen)     \n",
    "            colnames(final_output) <- c(\"Analysis\", \"Selection\", \"Sample Threshold\", \"N Sites\",  \"N Samples per Site\", \"N Total Samples\", \"Optimised Sites\", \"Optimised Allele Prop\", \"Optimised N Alleles\", \"Random Allele Prop\", \"Random N Alleles\")        \n",
    "            subDir <-paste0(outputloc2, \"OptSiteMix/\")\n",
    "            write.csv(final_output, file = paste0(subDir, \"OptSiteMix_MinSites_Final_Output.csv\"), row.names= FALSE)    \n",
    "        }   \n",
    "    } else {\n",
    "        print(\"not running OptSiteMix for minimum Sites\")\n",
    "    }\n",
    "  \n",
    "\n",
    "\n",
    "#     ██████╗ ██████╗ ████████╗███████╗██╗████████╗███████╗███╗   ███╗██╗██╗  ██╗    ███████╗ █████╗ ███╗   ███╗██████╗ ██╗     ███████╗███████╗\n",
    "#    ██╔═══██╗██╔══██╗╚══██╔══╝██╔════╝██║╚══██╔══╝██╔════╝████╗ ████║██║╚██╗██╔╝    ██╔════╝██╔══██╗████╗ ████║██╔══██╗██║     ██╔════╝██╔════╝\n",
    "#    ██║   ██║██████╔╝   ██║   ███████╗██║   ██║   █████╗  ██╔████╔██║██║ ╚███╔╝     ███████╗███████║██╔████╔██║██████╔╝██║     █████╗  ███████╗\n",
    "#    ██║   ██║██╔═══╝    ██║   ╚════██║██║   ██║   ██╔══╝  ██║╚██╔╝██║██║ ██╔██╗     ╚════██║██╔══██║██║╚██╔╝██║██╔═══╝ ██║     ██╔══╝  ╚════██║\n",
    "#    ╚██████╔╝██║        ██║   ███████║██║   ██║   ███████╗██║ ╚═╝ ██║██║██╔╝ ██╗    ███████║██║  ██║██║ ╚═╝ ██║██║     ███████╗███████╗███████║\n",
    "#     ╚═════╝ ╚═╝        ╚═╝   ╚══════╝╚═╝   ╚═╝   ╚══════╝╚═╝     ╚═╝╚═╝╚═╝  ╚═╝    ╚══════╝╚═╝  ╚═╝╚═╝     ╚═╝╚═╝     ╚══════╝╚══════╝╚══════╝\n",
    "                                                                                                                                           \n",
    "  \n",
    "  \n",
    "    if ((OptSiteMixMinSamples == 'yes') == TRUE |(OptSiteMixMinSamples == 'Yes') == TRUE |(OptSiteMixMinSamples == 'Y') == TRUE ){\n",
    "        print(\"Running OptSiteMix for minimum samples\")    \n",
    "        subDir <-paste0(outputloc2, \"OptSiteMix/Minimum_Samples/\")\n",
    "        if(!dir.exists(file.path(subDir))){\n",
    "            dir.create(file.path(subDir))\n",
    "        }\n",
    "\n",
    "        gta  <- dms$gt\n",
    "        pops <- as.vector(na.omit(dms$meta$analyses[,analysis]))    \n",
    "        tmpmac <- gt_to_pop_minor_allele_counts(gta, pops)    \n",
    "\n",
    "        if (any(which(colSums(tmpmac$N < 2)>0)) == TRUE | any(which(colSums(tmpmac$MAC == 0)==nrow(tmpmac$MAC))) == TRUE) {\n",
    "            i_loc_miss <- which(colSums(tmpmac$N < 2)>0)\n",
    "            i_mac_zero <- which(colSums(tmpmac$MAC == 0)==nrow(tmpmac$MAC))\n",
    "            i_rm <- union(i_loc_miss, i_mac_zero)\n",
    "            gta <- gta[, -i_rm]  \n",
    "            pmac <- gt_to_pop_minor_allele_counts(gta, pops)\n",
    "        } else {\n",
    "            pmac <- gt_to_pop_minor_allele_counts(gta, pops)\n",
    "        }\n",
    "        uq <- length(unique(pops)) \n",
    "        opt_psfs_MAC <- list()\n",
    "        minw <- rep(0, uq)        \n",
    "    \n",
    "    \n",
    "        for ( m in 1:length(cn) ) {\n",
    "            N_t <- as.numeric(cn[m])\n",
    "            cat(\"\\n Running \", N_t, \" ...\\n\")\n",
    "            max_wts <- rep(1, uq)\n",
    "            f <- uq-N_t\n",
    "            initial_wts <- sample(c(rep(1,N_t),rep(0, f)))\n",
    "            #N_t_MACvar <- paste0(\"opt_psfs_MAC_\", N_t)\n",
    "            opt_psfs_MAC[[m]] <- optimize_single_objective( gt=pmac$MAC, N_t=N_t, initial_weights=initial_wts, weights_max=max_wts, measure=\"psfs\", max_steps=num_steps, max_t=0.005, m=20, p_depends_delta=TRUE, pMAC_mode=TRUE, Nmat=pmac$N, weights_min=minw)       \n",
    "            png(file = paste0(subDir, species, analysis,\"optpsfs_minsamples_MAC_temperature_\", N_t, \"_Sites.png\"), width = 13.3, height = 7.5, res = 600, units = \"in\")\n",
    "            plot(opt_psfs_MAC[[m]]$value)         \n",
    "            dev.off()     \n",
    "\n",
    "            if (length(cn) >1){   \n",
    "                ### Generate table of optimised site selection\n",
    "                solution_table_samp <- mat.or.vec(nrow(pmac$MAC), length(cn))\n",
    "                for (i in 1:length(cn)) {\n",
    "                    solution_table_samp[,i] <- cbind(opt_psfs_MAC[[i]]$weight[num_steps,])        \n",
    "                }\n",
    "            }else{\n",
    "                solution_table_samp = NULL\n",
    "                for (i in 1:length(cn)) {   \n",
    "                    solution_table_samp <- as.data.frame(cbind(opt_psfs_MAC[[i]]$weight[num_steps,]))       \n",
    "                }\n",
    "            }   \n",
    "      \n",
    "            colnames(solution_table_samp) <- paste0(\"Sites\")\n",
    "            rownames(solution_table_samp) <- rownames(pmac$MAC)     \n",
    "            write.table(solution_table_samp, paste0(subDir, species, analysis,\" ogmsfs min samples.csv\"),sep=\",\",quote=FALSE, row.name=TRUE,col.name=NA)\n",
    "\n",
    "            #plot optimised site selection\n",
    "            Opt_solution_pdf <- c() \n",
    "            for (ib in 1:length(cn)) {\n",
    "                Opt_solution_pdf[ib] <- opt_psfs_MAC[[ib]]$value[num_steps]\n",
    "            }\n",
    "      \n",
    "      \n",
    "            Opt_solution_pdffinal <- as.data.frame(cbind(paste0(\"Sites\"), Opt_solution_pdf))\n",
    "            colnames(Opt_solution_pdffinal) <- c(\"Sites\", \"sfs_prop_m\")\n",
    "            Opt_Solution_Final <- as.data.frame(lapply(Opt_solution_pdffinal, unlist))\n",
    "            Opt_Solution_Final$sfs_prop_m <- as.numeric(Opt_Solution_Final$sfs_prop_m)\n",
    "            Opt_Solution_Final$Sites <- fct_inorder(Opt_Solution_Final$Sites)\n",
    "            opt_solution_dotplot <- ggplot(Opt_Solution_Final, aes(x=Sites, y=sfs_prop_m)) + geom_dotplot(binaxis='y', binwidth=0.005, stackdir='center') + labs(y=\"SFS Proportion m\", x=\"Sites\")\n",
    "            opt_solution_dotplot\n",
    "\n",
    "            ### Randomisation script - generates randomised site selection to compare to optimised site selection\n",
    "            rand_results <- c()\n",
    "            solution_pdf <- c()\n",
    "            rand_results_val <- c()\n",
    "\n",
    "            for ( ic in 1:length(cn) ) {\n",
    "                iNt <- as.numeric(cn[ic])\n",
    "                for (j in 1:rand_numsteps) {\n",
    "                    f <- uq-iNt\n",
    "                    initial_wts <- sample(c(rep(1,iNt),rep(0, f)))\n",
    "                    RandomSites <- sample(1:uq)[1:iNt]\n",
    "                    rand_minw <- rep(0, uq)\n",
    "                    rand_minw[RandomSites] = 1\n",
    "                    rand_results[[j]] <- optimize_single_objective( gt=pmac$MAC, N_t=iNt, initial_weights=initial_wts, weights_max=max_wts, measure=\"psfs\", max_steps=1, max_t=0.005, m=20, p_depends_delta=TRUE, pMAC_mode=TRUE, Nmat=pmac$N, weights_min=rand_minw)\n",
    "                    rand_results_val[j] <- as.data.frame(rand_results[[j]]$value)    \n",
    "                }\n",
    "                rand_results_valfinal <- cbind((paste0(\"Sites\")), rand_results_val)\n",
    "                solution_pdf <- as.data.frame(rbind(solution_pdf, rand_results_valfinal))\n",
    "            }\n",
    "      \n",
    "      \n",
    "            colnames(solution_pdf) <- c(\"Sites\", \"sfs_prop_m\")\n",
    "            solution_pdf2 <- as.data.frame(lapply(solution_pdf, unlist))\n",
    "            solution_pdf2$Sites <- fct_inorder(solution_pdf2$Sites)\n",
    "            rand_solution_plot <- ggplot(solution_pdf2, aes(x=Sites, y=sfs_prop_m))+ geom_violin() + labs(y=\"SFS Proportion m\", x=\"Sites\")\n",
    "            write.table(solution_pdf2, paste0(subDir, species, analysis,\" min samples Randomisation Table.csv\"),sep=\",\",quote=FALSE, row.name=FALSE,col.name=TRUE)\n",
    "            write.table(Opt_Solution_Final, paste0(subDir, species, analysis,\" Optimised min samples Table.csv\"),sep=\",\",quote=FALSE, row.name=FALSE,col.name=TRUE)\n",
    "\n",
    "            ### Combined plot of optimised vs randomised site selection\n",
    "            combined_plot <- ggplot(solution_pdf2, aes(x=Sites, y=sfs_prop_m)) + \n",
    "            geom_violin() + \n",
    "            geom_dotplot(data=Opt_Solution_Final, binaxis='y', binwidth=0.005, stackdir='center', fill=\"red\") + \n",
    "            labs(title=paste0(\"Optimised vs Random for \", iNt, \" Sites\"), subtitle= paste0(species,\" \", analysis), y=\"SFS Proportion (m)\", x=\"Sites Selected (n)\") + \n",
    "            theme_minimal(base_size=20) + \n",
    "            theme(axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 0, l = 0)),  plot.title = element_text(margin = margin(t = 0, r = 0, b = 10, l = 0)), plot.subtitle = element_text(margin = margin(t = 0, r = 0, b = 20, l = 0)))    \n",
    "            combined_plot\n",
    "            ggsave(paste0(species, analysis,\" optimised min samples VS random.pdf\"), path=paste0(subDir), width = 13, height = 12, dpi = 600, units = \"in\")  \n",
    "      \n",
    "            #Now take the optimised site combination and input these as forced allele proportion Sites \n",
    "            #to compare between optimised vs random allele proportion      \n",
    "            solution_table_samp$row_names <- row.names(solution_table_samp)\n",
    "            OrderforOptimisedSites <- solution_table_samp[order(solution_table_samp$Sites, decreasing =TRUE),]\n",
    "            OptimisedSites <- OrderforOptimisedSites$row_names[1:cn]\n",
    "      \n",
    "            #create a temp meta dataframe to remove Sites/samples that include less than X individuals\n",
    "            temp<-as.data.frame(m1$analyses)\n",
    "            # Below lines remove Sites with less than threshold number of samples, and subsample Sites that are above the threshold  \n",
    "            samplethreshold <-5 # chnage this to what number of samples you want toi have uniform across all pops  \n",
    "        \n",
    "            for (x in unique(na.omit(temp[,analysis]))) {        \n",
    "                pop_samples <- which(temp[,analysis] == x)    \n",
    "                if (length(pop_samples) < samplethreshold) {     \n",
    "                    temp[, analysis]<-gsub(x, replacement=NA, temp[, analysis])      \n",
    "                    #print(paste0(\"Removing \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))    \n",
    "                }    \n",
    "                if (length(pop_samples) == samplethreshold) {      \n",
    "                    #print(paste0(\"Keeping \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))    \n",
    "                }    \n",
    "                if (length(pop_samples) > samplethreshold) {      \n",
    "                    subsamplepops <- pop_samples[sample(1:length(pop_samples), size=samplethreshold, replace = F)]      \n",
    "                    for (b in 1:length(pop_samples)){        \n",
    "                        if (pop_samples[b] %in% subsamplepops == FALSE){         \n",
    "                            temp[, analysis][pop_samples[b]] <- NA        \n",
    "                        }        \n",
    "                        #print(paste0(\"Reducing \",x, \" to a sample size of \", samplethreshold,\" samples\"))      \n",
    "                    }    \n",
    "                } else {}  \n",
    "            }               \n",
    "            m1$analyses<-temp      \n",
    "            dm <- dart.meta.data.merge(d3, m1)      \n",
    "            fields    <- c(analysis)      \n",
    "            dms     <- data.by.meta.fields(dm, fields, RandRbase, species, dataset, object=analysis); #print(dms$meta$analyses[,analysis])     \n",
    "            #correct inconsistencies in J's scripts for naming treatment which is for naming files\n",
    "            treatment <- paste0(\"raw_SNPFilt_1SNPperClone_Field_\", analysis)         \n",
    "            dms$treatment <- treatment         \n",
    "            gta <- dms$gt             \n",
    "            gt_sw_comp <- gta    \n",
    "            ncol(gt_sw_comp) \n",
    "\n",
    "            ###load required code\n",
    "            source_url(\"https://github.com/RichardDimon/get_maf/blob/main/get_maf.r?raw=TRUE\")\n",
    "            source_url(\"https://github.com/RichardDimon/common_allele_count/blob/main/common_allele_count.r?raw=TRUE\")\n",
    "            ###the next line of code runs a loop that create a table with all \n",
    "            ###possible combinations of sampling assuming all included pops have atleast 5 samples available\n",
    "            sampling<-setNames(data.frame(matrix(ncol = 3, nrow = 0)), c(\"Sites\", \"samples\", \"total\"))\n",
    "            for (c in 1:length(unique(dms$meta$analyses[,analysis]))) { \n",
    "                for (ind in 1:samplethreshold) {\n",
    "                    sampling[nrow(sampling) + 1,] = list(c,ind,c*ind) \n",
    "                }\n",
    "            }\n",
    "      \n",
    "            ###this bit orders the sampling strategy and removes strategies with less than x samples\n",
    "      \n",
    "            sampling<-sampling[order(sampling$total),]\n",
    "            ###script randomly selects selected number of Sites and in each site a number of samples\n",
    "            dms_meta <- cbind.data.frame(sample=dms$meta$sample_names, site=dms$meta$analyses[,analysis],lat=dms$meta$lat, long=dms$meta$long)\n",
    "            colnames(dms_meta) <- c(\"sample\",\"site\",\"lat\",\"long\")\n",
    "            unique_Sites <- unique(na.omit(dms_meta$site)) #maximum number of Sites\n",
    "            gvals <- list() #accumulate data to be saved #samples & Sites to choose, number of common alleles\n",
    "\n",
    "            #insert loop here to run through table listing parameters in bottom two lines#\n",
    "            OGM_DF<-setNames(data.frame(matrix(ncol = 8, nrow = 0)), c(\"m\",\"t_num_indv\", \"n_Sites_sel\", \"n_indiv_sel\", \"rand_Sites_sel\", \n",
    "            \"rand_indiv_sel\", \"jvals\", \"Aprop\"))\n",
    "            set.seed(12345)   \n",
    "            ###Set Sites to select by name and set numbers of Sites and individuals to select###\n",
    "            Sites_sel <- OptimisedSites\n",
    "            #Sites_sel <- unique(na.omit(dms_meta$site))       \n",
    "            rand_indiv_sel <- c()\n",
    "            n_Sites_sel <- as.numeric(cn)\n",
    "            t_num_indv <- as.numeric(dn)\n",
    "            n_indiv_sel <- t_num_indv/n_Sites_sel         \n",
    "\n",
    "            for (m in 1:1000) {\n",
    "                rand_Sites_sel <- Sites_sel[sample(1:length(Sites_sel))[1:n_Sites_sel]]; #print(rand_Sites_sel)  \n",
    "                rand_indiv_sel <- c()      \n",
    "                for (s in 1:n_Sites_sel) {    \n",
    "                    rand_indiv <- as.character(dms_meta$sample[which(dms_meta$site == rand_Sites_sel[s])][sample(1:length(which(dms_meta$site == rand_Sites_sel[s])))[1:n_indiv_sel]])     \n",
    "                    rand_indiv_sel <- c(rand_indiv_sel,rand_indiv) ; #print(rand_indiv_sel)  \n",
    "                }    \n",
    "                # dms_meta$site[which(dms_meta$sample %in% rand_indiv_sel)]\n",
    "                fixed_indi <- which(dms$sample_names %in% rand_indiv_sel)      \n",
    "                ran_vec <- rep(0, nrow(gt_sw_comp))  \n",
    "                ran_vec[fixed_indi] <- 1 \n",
    "                common_alleles  <- common_allele_count(gt_sw_comp, ran_vec)     \n",
    "                sw_maf    <- get_maf(gt_sw_comp) \n",
    "                threshold_maf <- thresh_maf #change to higher if singleton is stronger possibility e.g Cattai   \n",
    "                #common allel count is 1, minor allele count observed once  \n",
    "                i_sw_common <- which(sw_maf > threshold_maf)  \n",
    "                jvals <- length( intersect( which(common_alleles[[2]] > 0), i_sw_common))   \n",
    "                Aprop<-jvals/length(i_sw_common)       \n",
    "                gvals[[m]] <- data.frame(m,t_num_indv,n_Sites_sel,n_indiv_sel,rand_Sites_sel,rand_indiv_sel,jvals, Aprop)     \n",
    "            }\n",
    "      \n",
    "     \n",
    "            #save big_data2 somewhere... \n",
    "            big_data2 = do.call(rbind, gvals)\n",
    "            write.csv(big_data2, file = paste0(subDir,\"forced\",n_Sites_sel,\"Sites_\",n_indiv_sel,\"individuals.csv\"), row.names = FALSE) \n",
    "            OGM_DF<-rbind(OGM_DF, big_data2)\n",
    "            clean_data_optimised <- OGM_DF %>% group_by(t_num_indv,n_Sites_sel,m) %>% summarize(Average_Allele=mean(Aprop),Average_Allelen=mean(jvals)) %>% data.frame\n",
    "            #clean_data$t_num_indv<-as.numeric(clean_data$t_num_indv)\n",
    "            write.csv(clean_data_optimised, file = paste0(subDir, \"Optimised_AlleleProp_Summary.csv\"), row.names = FALSE)\n",
    "\n",
    "            #Now repreat the same using randomisation of all Sites withinthe dataset (not just the selected forced Sites)\n",
    "            Sites_sel <- unique(na.omit(dms_meta$site))      \n",
    "            rand_indiv_sel <- c()\n",
    "\n",
    "            for (m in 1:1000) {\n",
    "                rand_Sites_sel <- Sites_sel[sample(1:length(Sites_sel))[1:n_Sites_sel]]; #print(rand_Sites_sel)\n",
    "                rand_indiv_sel <- c()      \n",
    "                for (s in 1:n_Sites_sel) {   \n",
    "                    rand_indiv <- as.character(dms_meta$sample[which(dms_meta$site == rand_Sites_sel[s])][sample(1:length(which(dms_meta$site == rand_Sites_sel[s])))[1:n_indiv_sel]])   \n",
    "                    rand_indiv_sel <- c(rand_indiv_sel,rand_indiv) ; #print(rand_indiv_sel)  \n",
    "                }    \n",
    "                # dms_meta$site[which(dms_meta$sample %in% rand_indiv_sel)]   \n",
    "                fixed_indi <- which(dms$sample_names %in% rand_indiv_sel)     \n",
    "                ran_vec <- rep(0, nrow(gt_sw_comp))   \n",
    "                ran_vec[fixed_indi] <- 1   \n",
    "                common_alleles  <- common_allele_count(gt_sw_comp, ran_vec)       \n",
    "                sw_maf    <- get_maf(gt_sw_comp)   \n",
    "                threshold_maf <- thresh_maf #change to higher if singleton is stronger possibility e.g Cattai  \n",
    "                #common allel count is 1, minor allele count observed once  \n",
    "                i_sw_common <- which(sw_maf > threshold_maf)  \n",
    "                jvals <- length( intersect( which(common_alleles[[2]] > 0), i_sw_common))  \n",
    "                Aprop<-jvals/length(i_sw_common)       \n",
    "                gvals[[m]] <- data.frame(m,t_num_indv,n_Sites_sel,n_indiv_sel,rand_Sites_sel,rand_indiv_sel,jvals, Aprop)     \n",
    "            }        \n",
    "            #save big_data2 somewhere...\n",
    "            big_data2 = do.call(rbind, gvals)\n",
    "            write.csv(big_data2, file = paste0(subDir,\"randomisation_\",n_Sites_sel,\"Sites_\",n_indiv_sel,\"individuals.csv\"), row.names = FALSE)\n",
    "            OGM_DF<-rbind(OGM_DF, big_data2)\n",
    "            clean_data_random <- OGM_DF %>% group_by(t_num_indv,n_Sites_sel,m) %>% summarize(Average_Allele=mean(Aprop),Average_Allelen=mean(jvals)) %>% data.frame\n",
    "            #clean_data$t_num_indv<-as.numeric(clean_data$t_num_indv)\n",
    "            write.csv(clean_data_random, file = paste0(subDir, \"Random_AlleleProp_Summary.csv\"), row.names = FALSE)\n",
    "\n",
    "            \n",
    "            \n",
    "        }\n",
    "                \n",
    "        #FORCED SITE Optimisation            \n",
    "        if ((ForcedOptSiteMix == 'yes') == TRUE |(ForcedOptSiteMix == 'Yes') == TRUE |(ForcedOptSiteMix == 'Y') == TRUE ){\n",
    "            #reads the string variable from the parameters file and forced optimisation selection in the binary format for minw\n",
    "            ForcedOptSites <- str_split(ListForcedSites, \",\", simplify=TRUE);\n",
    "            uqpops <- unique(pops)\n",
    "            if (length(ForcedOptSites) > cn) {\n",
    "                print(paste0(\"Warning: too many forced sites! need to supply \", cn, \" or fewer sites\"))\n",
    "            } else { \n",
    "                for (p in 1:length(ForcedOptSites)){\n",
    "                    uqpops <- gsub(ForcedOptSites[p], \"1\", uqpops)\n",
    "                }\n",
    "                for (v in 1:length(uqpops)){\n",
    "                    if (uqpops[v] != 1){\n",
    "                        uqpops <- gsub(uqpops[v], \"0\", uqpops)\n",
    "                    } else {}\n",
    "    \n",
    "                }\n",
    "                minw <- uqpops\n",
    "                print(\"Running Forced OptSiteMix for minimum samples\")   \n",
    "                subDir <-paste0(outputloc2, \"OptSiteMix/Minimum_Samples/ForcedSiteSelection/\")\n",
    "                if(!dir.exists(file.path(subDir))){\n",
    "                    dir.create(file.path(subDir))\n",
    "                }\n",
    "\n",
    "                gta  <- dms$gt\n",
    "                pops <- as.vector(na.omit(dms$meta$analyses[,analysis]))    \n",
    "                tmpmac <- gt_to_pop_minor_allele_counts(gta, pops)    \n",
    "\n",
    "                if (any(which(colSums(tmpmac$N < 2)>0)) == TRUE | any(which(colSums(tmpmac$MAC == 0)==nrow(tmpmac$MAC))) == TRUE) {\n",
    "                    i_loc_miss <- which(colSums(tmpmac$N < 2)>0)\n",
    "                    i_mac_zero <- which(colSums(tmpmac$MAC == 0)==nrow(tmpmac$MAC))\n",
    "                    i_rm <- union(i_loc_miss, i_mac_zero)\n",
    "                    gta <- gta[, -i_rm]  \n",
    "                    pmac <- gt_to_pop_minor_allele_counts(gta, pops)\n",
    "                } else {\n",
    "                    pmac <- gt_to_pop_minor_allele_counts(gta, pops)\n",
    "                }\n",
    "                uq <- length(unique(pops)) \n",
    "                opt_psfs_MAC <- list()\n",
    "                print(\"running forced site selection...\")\n",
    "            }\n",
    "    \n",
    "    \n",
    "            for ( m in 1:length(cn) ) {\n",
    "                N_t <- as.numeric(cn[m])\n",
    "                cat(\"\\n Running \", N_t, \" ...\\n\")\n",
    "                max_wts <- rep(1, uq)\n",
    "                f <- uq-N_t\n",
    "                initial_wts <- sample(c(rep(1,N_t),rep(0, f)))\n",
    "                #N_t_MACvar <- paste0(\"opt_psfs_MAC_\", N_t)\n",
    "                opt_psfs_MAC[[m]] <- optimize_single_objective( gt=pmac$MAC, N_t=N_t, initial_weights=initial_wts, weights_max=max_wts, measure=\"psfs\", max_steps=num_steps, max_t=0.005, m=20, p_depends_delta=TRUE, pMAC_mode=TRUE, Nmat=pmac$N, weights_min=minw)       \n",
    "\n",
    "                png(file = paste0(subDir, species, analysis,\"optpsfs_minsamples_MAC_temperature_\", N_t, \"_Forced_Sites.png\"), width = 13.3, height = 7.5, res = 600, units = \"in\")\n",
    "                plot(opt_psfs_MAC[[m]]$value)         \n",
    "                dev.off()     \n",
    "\n",
    "\n",
    "                if (length(cn) >1){   \n",
    "                    ### Generate table of optimised site selection\n",
    "                    solution_table_samp <- mat.or.vec(nrow(pmac$MAC), length(cn))\n",
    "                    for (i in 1:length(cn)) {\n",
    "                    solution_table_samp[,i] <- cbind(opt_psfs_MAC[[i]]$weight[num_steps,])        \n",
    "                }\n",
    "\n",
    "                }else{\n",
    "                    solution_table_samp = NULL\n",
    "                    for (i in 1:length(cn)) {   \n",
    "                        solution_table_samp <- as.data.frame(cbind(opt_psfs_MAC[[i]]$weight[num_steps,]))       \n",
    "                    }\n",
    "                }   \n",
    "      \n",
    "                colnames(solution_table_samp) <- paste0(\"Sites\")\n",
    "                rownames(solution_table_samp) <- rownames(pmac$MAC)     \n",
    "                write.table(solution_table_samp, paste0(subDir, species, analysis,\" ogmsfs min samples.csv\"),sep=\",\",quote=FALSE, row.name=TRUE,col.name=NA)      \n",
    "                #plot optimised site selection\n",
    "                Opt_solution_pdf <- c() \n",
    "                for (ib in 1:length(cn)) {\n",
    "                    Opt_solution_pdf[ib] <- opt_psfs_MAC[[ib]]$value[num_steps]\n",
    "                }\n",
    "\n",
    "                Opt_solution_pdffinal <- as.data.frame(cbind(paste0(\"Sites\"), Opt_solution_pdf))\n",
    "                colnames(Opt_solution_pdffinal) <- c(\"Sites\", \"sfs_prop_m\")\n",
    "                Opt_Solution_Final <- as.data.frame(lapply(Opt_solution_pdffinal, unlist))\n",
    "                Opt_Solution_Final$sfs_prop_m <- as.numeric(Opt_Solution_Final$sfs_prop_m)\n",
    "                Opt_Solution_Final$Sites <- fct_inorder(Opt_Solution_Final$Sites)\n",
    "                opt_solution_dotplot <- ggplot(Opt_Solution_Final, aes(x=Sites, y=sfs_prop_m)) + geom_dotplot(binaxis='y', binwidth=0.005, stackdir='center') + labs(y=\"SFS Proportion m\", x=\"Sites\")\n",
    "                opt_solution_dotplot\n",
    "\n",
    "                ### Randomisation script - generates randomised site selection to compare to optimised site selection\n",
    "                rand_results <- c()\n",
    "                solution_pdf <- c()\n",
    "                rand_results_val <- c()\n",
    "                for ( ic in 1:length(cn) ) {\n",
    "        \n",
    "                    iNt <- as.numeric(cn[ic])\n",
    "                    for (j in 1:rand_numsteps) {\n",
    "                      f <- uq-iNt\n",
    "                      initial_wts <- sample(c(rep(1,iNt),rep(0, f)))\n",
    "                      RandomSites <- sample(1:uq)[1:iNt]\n",
    "                      rand_minw <- rep(0, uq)\n",
    "                      rand_minw[RandomSites] = 1\n",
    "                      rand_results[[j]] <- optimize_single_objective( gt=pmac$MAC, N_t=iNt, initial_weights=initial_wts, weights_max=max_wts, measure=\"psfs\", max_steps=1, max_t=0.005, m=20, p_depends_delta=TRUE, pMAC_mode=TRUE, Nmat=pmac$N, weights_min=rand_minw)\n",
    "                      rand_results_val[j] <- as.data.frame(rand_results[[j]]$value)    \n",
    "                    }\n",
    "                    rand_results_valfinal <- cbind((paste0(\"Sites\")), rand_results_val)\n",
    "                    solution_pdf <- as.data.frame(rbind(solution_pdf, rand_results_valfinal))\n",
    "                }\n",
    "                colnames(solution_pdf) <- c(\"Sites\", \"sfs_prop_m\")\n",
    "                solution_pdf2 <- as.data.frame(lapply(solution_pdf, unlist))\n",
    "                solution_pdf2$Sites <- fct_inorder(solution_pdf2$Sites)\n",
    "                rand_solution_plot <- ggplot(solution_pdf2, aes(x=Sites, y=sfs_prop_m))+ geom_violin() + labs(y=\"SFS Proportion m\", x=\"Sites\")\n",
    "\n",
    "                write.table(solution_pdf2, paste0(subDir, species, analysis,\" min samples Randomisation Table.csv\"),sep=\",\",quote=FALSE, row.name=FALSE,col.name=TRUE)\n",
    "                write.table(Opt_Solution_Final, paste0(subDir, species, analysis,\" Forced Optimised min samples Table.csv\"),sep=\",\",quote=FALSE, row.name=FALSE,col.name=TRUE)\n",
    "\n",
    "                ### Combined plot of optimised vs randomised site selection\n",
    "                combined_plot <- ggplot(solution_pdf2, aes(x=Sites, y=sfs_prop_m)) + \n",
    "                geom_violin() + \n",
    "                geom_dotplot(data=Opt_Solution_Final, binaxis='y', binwidth=0.005, stackdir='center', fill=\"red\") + \n",
    "                labs(title=paste0(\"Forced Optimised vs Random for \", iNt, \" Sites\"), subtitle= paste0(species,\" \", analysis), y=\"SFS Proportion (m)\", x=\"Sites Selected (n)\") + \n",
    "                theme_minimal(base_size=20) + \n",
    "                theme(axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 0, l = 0)),  plot.title = element_text(margin = margin(t = 0, r = 0, b = 10, l = 0)), plot.subtitle = element_text(margin = margin(t = 0, r = 0, b = 20, l = 0)))    \n",
    "                combined_plot\n",
    "                ggsave(paste0(species, analysis,\" forced optimised min samples VS random.pdf\"), path=paste0(subDir), width = 13, height = 12, dpi = 600, units = \"in\")  \n",
    "      \n",
    "                #Now take the optimised site combination and input these as forced allele proportion Sites \n",
    "                #to compare between optimised vs random allele proportion      \n",
    "                solution_table_samp$row_names <- row.names(solution_table_samp)\n",
    "                OrderforforcedOptimisedSites <- solution_table_samp[order(solution_table_samp$Sites, decreasing =TRUE),]\n",
    "                forcedOptimisedSites <- OrderforforcedOptimisedSites$row_names[1:cn]\n",
    "\n",
    "                #create a temp meta dataframe to remove Sites/samples that include less than X individuals\n",
    "                temp<-as.data.frame(m1$analyses)\n",
    "\n",
    "                # Below lines remove Sites with less than threshold number of samples, and subsample Sites that are above the threshold  \n",
    "                samplethreshold <-5 # chnage this to what number of samples you want toi have uniform across all pops  \n",
    "                for (x in unique(na.omit(temp[,analysis]))) {    \n",
    "                    pop_samples <- which(temp[,analysis] == x)    \n",
    "                    if (length(pop_samples) < samplethreshold) {     \n",
    "                        temp[, analysis]<-gsub(x, replacement=NA, temp[, analysis])      \n",
    "                        #print(paste0(\"Removing \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))    \n",
    "                    }    \n",
    "                    if (length(pop_samples) == samplethreshold) {      \n",
    "                        #print(paste0(\"Keeping \",x, \" with \", \" with a sample size of \",length(pop_samples),\" samples\"))    \n",
    "                    }    \n",
    "                    if (length(pop_samples) > samplethreshold) {      \n",
    "                        subsamplepops <- pop_samples[sample(1:length(pop_samples), size=samplethreshold, replace = F)]      \n",
    "                    for (b in 1:length(pop_samples)){        \n",
    "                        if (pop_samples[b] %in% subsamplepops == FALSE){         \n",
    "                            temp[, analysis][pop_samples[b]] <- NA        \n",
    "                        }        \n",
    "                        #print(paste0(\"Reducing \",x, \" to a sample size of \", samplethreshold,\" samples\"))      \n",
    "                    }    \n",
    "                    } else {}  \n",
    "                }\n",
    "                \n",
    "        \n",
    "                m1$analyses<-temp      \n",
    "                dm <- dart.meta.data.merge(d3, m1)      \n",
    "                fields    <- c(analysis)      \n",
    "                dms     <- data.by.meta.fields(dm, fields, RandRbase, species, dataset, object=analysis); #print(dms$meta$analyses[,analysis])     \n",
    "                #correct inconsistencies in J's scripts for naming treatment which is for naming files\n",
    "                treatment <- paste0(\"raw_SNPFilt_1SNPperClone_Field_\", analysis)         \n",
    "                dms$treatment <- treatment         \n",
    "                gta <- dms$gt             \n",
    "                gt_sw_comp <- gta    \n",
    "                ncol(gt_sw_comp) \n",
    "\n",
    "                ###load required code\n",
    "                source_url(\"https://github.com/RichardDimon/get_maf/blob/main/get_maf.r?raw=TRUE\")\n",
    "                source_url(\"https://github.com/RichardDimon/common_allele_count/blob/main/common_allele_count.r?raw=TRUE\")\n",
    "                ###the next line of code runs a loop that create a table with all \n",
    "                ###possible combinations of sampling assuming all included pops have atleast 5 samples available\n",
    "                sampling<-setNames(data.frame(matrix(ncol = 3, nrow = 0)), c(\"Sites\", \"samples\", \"total\"))\n",
    "                for (c in 1:length(unique(dms$meta$analyses[,analysis]))) { \n",
    "                    for (ind in 1:samplethreshold) {\n",
    "                        sampling[nrow(sampling) + 1,] = list(c,ind,c*ind) \n",
    "                    }\n",
    "                }\n",
    "      \n",
    "                ###this bit orders the sampling strategy and removes strategies with less than x samples\n",
    "                sampling<-sampling[order(sampling$total),]\n",
    "                ###script randomly selects selected number of Sites and in each site a number of samples\n",
    "                dms_meta <- cbind.data.frame(sample=dms$meta$sample_names, site=dms$meta$analyses[,analysis],lat=dms$meta$lat, long=dms$meta$long)\n",
    "                colnames(dms_meta) <- c(\"sample\",\"site\",\"lat\",\"long\")\n",
    "                unique_Sites <- unique(na.omit(dms_meta$site)) #maximum number of Sites\n",
    "                gvals <- list() #accumulate data to be saved #samples & Sites to choose, number of common alleles\n",
    "\n",
    "                #insert loop here to run through table listing parameters in bottom two lines#\n",
    "                OGM_DF<-setNames(data.frame(matrix(ncol = 8, nrow = 0)), c(\"m\",\"t_num_indv\", \"n_Sites_sel\", \"n_indiv_sel\", \"rand_Sites_sel\", \n",
    "                \"rand_indiv_sel\", \"jvals\", \"Aprop\"))\n",
    "                set.seed(12345)   \n",
    "                ###Set Sites to select by name and set numbers of Sites and individuals to select###\n",
    "                Sites_sel <- forcedOptimisedSites\n",
    "                #Sites_sel <- unique(na.omit(dms_meta$site))       \n",
    "                rand_indiv_sel <- c()\n",
    "                n_Sites_sel <- as.numeric(cn)\n",
    "                t_num_indv <- as.numeric(dn)\n",
    "                n_indiv_sel <- t_num_indv/n_Sites_sel         \n",
    "\n",
    "                for (m in 1:1000) {\n",
    "                    rand_Sites_sel <- Sites_sel[sample(1:length(Sites_sel))[1:n_Sites_sel]]; #print(rand_Sites_sel)  \n",
    "                    rand_indiv_sel <- c()      \n",
    "                    for (s in 1:n_Sites_sel) {    \n",
    "                        rand_indiv <- as.character(dms_meta$sample[which(dms_meta$site == rand_Sites_sel[s])][sample(1:length(which(dms_meta$site == rand_Sites_sel[s])))[1:n_indiv_sel]])     \n",
    "                        rand_indiv_sel <- c(rand_indiv_sel,rand_indiv) ; #print(rand_indiv_sel)  \n",
    "                    }    \n",
    "        \n",
    "                    # dms_meta$site[which(dms_meta$sample %in% rand_indiv_sel)]\n",
    "                    fixed_indi <- which(dms$sample_names %in% rand_indiv_sel)      \n",
    "                    ran_vec <- rep(0, nrow(gt_sw_comp))  \n",
    "                    ran_vec[fixed_indi] <- 1 \n",
    "                    common_alleles  <- common_allele_count(gt_sw_comp, ran_vec)     \n",
    "                    sw_maf    <- get_maf(gt_sw_comp) \n",
    "                    threshold_maf <- thresh_maf #change to higher if singleton is stronger possibility e.g Cattai   \n",
    "                    #common allel count is 1, minor allele count observed once  \n",
    "                    i_sw_common <- which(sw_maf > threshold_maf)  \n",
    "                    jvals <- length( intersect( which(common_alleles[[2]] > 0), i_sw_common))   \n",
    "                    Aprop<-jvals/length(i_sw_common)       \n",
    "                    gvals[[m]] <- data.frame(m,t_num_indv,n_Sites_sel,n_indiv_sel,rand_Sites_sel,rand_indiv_sel,jvals, Aprop)     \n",
    "                }\n",
    "      \n",
    "                #save big_data2 somewhere... \n",
    "                big_data2 = do.call(rbind, gvals)\n",
    "                write.csv(big_data2, file = paste0(subDir,\"forced\",n_Sites_sel,\"Sites_\",n_indiv_sel,\"individuals.csv\"), row.names = FALSE) \n",
    "                OGM_DF<-rbind(OGM_DF, big_data2)\n",
    "                clean_data_forcedoptimised <- OGM_DF %>% group_by(t_num_indv,n_Sites_sel,m) %>% summarize(Average_Allele=mean(Aprop),Average_Allelen=mean(jvals)) %>% data.frame\n",
    "                #clean_data$t_num_indv<-as.numeric(clean_data$t_num_indv)\n",
    "                write.csv(clean_data_forcedoptimised, file = paste0(subDir, \"Forced_Optimisation_AlleleProp_Summary.csv\"), row.names = FALSE)\n",
    "\n",
    "                #now combine all results into a summmary csv file (with forced optimisation)                                         \n",
    "                final_output <- cbind.data.frame(analysis, \"Minimum Samples\", samplingthreshold, cn, dn/cn, dn, paste0(OptimisedSites, collapse=', '), clean_data_optimised$Average_Allele, clean_data_optimised$Average_Allelen, ListForcedSites, paste0(forcedOptimisedSites, collapse=', '), clean_data_forcedoptimised$Average_Allele, clean_data_forcedoptimised$Average_Allelen, clean_data_random$Average_Allele, clean_data_random$Average_Allelen)     \n",
    "                colnames(final_output) <- c(\"Analysis\", \"Selection\", \"Sample Threshold\", \"N Sites\",  \"N Samples per Site\", \"N Total Samples\", \"Optimised Sites\", \"Optimised Allele Prop\", \"Optimised N Alleles\", \"Intial Forced Sites\", \"Forced Optimised Sites\", \"Forced Optimised Allele Prop\", \"Forced Optimised N Alleles\", \"Random Allele Prop\", \"Random N Alleles\")        \n",
    "                subDir <-paste0(outputloc2, \"OptSiteMix/\")\n",
    "                write.csv(final_output, file = paste0(subDir, \"Forced_OptSiteMix_MinSamples_Final_Output.csv\"), row.names= FALSE)   \n",
    "                \n",
    "            }\n",
    "\n",
    "        } else {\n",
    "\n",
    "            #now combine all results into a summmary csv file (without forced optimisation)                                          \n",
    "            final_output <- cbind.data.frame(analysis, \"Minimum Samples\", samplingthreshold, cn, dn/cn, dn, paste0(OptimisedSites, collapse=', '), clean_data_optimised$Average_Allele, clean_data_optimised$Average_Allelen, clean_data_random$Average_Allele, clean_data_random$Average_Allelen)     \n",
    "            colnames(final_output) <- c(\"Analysis\", \"Selection\", \"Sample Threshold\", \"N Sites\",  \"N Samples per Site\", \"N Total Samples\", \"Optimised Sites\", \"Optimised Allele Prop\", \"Optimised N Alleles\", \"Random Allele Prop\", \"Random N Alleles\")        \n",
    "            subDir <-paste0(outputloc2, \"OptSiteMix/\")\n",
    "            write.csv(final_output, file = paste0(subDir, \"OptSiteMix_MinSamples_Final_Output.csv\"), row.names= FALSE)   \n",
    "        }\n",
    "    } else {\n",
    "        print(\"not running OptSiteMix for minimum samples\")    \n",
    "    }\n",
    "    \n",
    "#}\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
